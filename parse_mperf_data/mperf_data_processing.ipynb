{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebralcortex.util.helper_methods import get_study_names\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import minute, second, mean, window\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from cerebralcortex import Kernel\n",
    "from pyspark.sql import functions as F\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='mperf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate PPG data Quality - DC level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_quality_motionsensehrv(data,wrist = 'left'):\n",
    "    def isDatapointsWithinRange(red,infrared,green):\n",
    "        red = np.asarray(red, dtype=np.float32)\n",
    "        infrared = np.asarray(infrared, dtype=np.float32)\n",
    "        green = np.asarray(green, dtype=np.float32)\n",
    "        a =  len(np.where((red >= 30000)& (red<=200000))[0]) < .33*3*25\n",
    "        b = len(np.where((infrared >= 110000)& (infrared<=230000))[0]) < .33*3*25\n",
    "        c = len(np.where((green >= 500)& (green<=20000))[0]) < .33*3*25\n",
    "        if a and b and c:\n",
    "            return False\n",
    "        return True\n",
    "    def compute_quality(red,infrared,green):\n",
    "        \"\"\"\n",
    "        :param window: a window containing list of DataPoints\n",
    "        :return: an integer reptresenting the status of the window 0= attached, 1 = not attached\n",
    "        \"\"\"\n",
    "        if len(red)==0:\n",
    "            return 1 #not attached\n",
    "        if not isDatapointsWithinRange(red,infrared,green):\n",
    "            return 1\n",
    "        red_mean = np.mean(red)\n",
    "        ir_mean = np.mean(infrared)\n",
    "        green_mean = np.mean(green)\n",
    "        if red_mean < 5000 and ir_mean < 5000:\n",
    "            return 1\n",
    "        if not (red_mean>green_mean and ir_mean>red_mean):\n",
    "            return 1\n",
    "        diff = 30000\n",
    "        if red_mean<130000:\n",
    "            diff = 10000\n",
    "        if not red_mean - green_mean > diff:\n",
    "            return 1\n",
    "        if not ir_mean - red_mean >diff:\n",
    "            return 1\n",
    "        return 0\n",
    "    schema = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"red\", FloatType()),\n",
    "        StructField(\"infrared\", FloatType()),\n",
    "        StructField(\"green\", FloatType()),\n",
    "        StructField(\"aclx\", FloatType()),\n",
    "        StructField(\"acly\", FloatType()),\n",
    "        StructField(\"aclz\", FloatType()),\n",
    "        StructField(\"gyrox\", FloatType()),\n",
    "        StructField(\"gyroy\", FloatType()),\n",
    "        StructField(\"gyroz\", FloatType()),\n",
    "        StructField(\"quality\", IntegerType())\n",
    "    ])\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def ppg_quality(key,data):\n",
    "        data = data.sort_values('time').reset_index(drop=True)\n",
    "        data['quality'] = compute_quality(data['red'].values,\n",
    "                                          data['infrared'].values,\n",
    "                                          data['green'].values)\n",
    "        data.drop(columns=['time'],inplace=True)\n",
    "        return data\n",
    "\n",
    "    data = data.withColumn('time',data.timestamp.cast('double'))\n",
    "    win = F.window(\"timestamp\", windowDuration='3 seconds', startTime='0 seconds')\n",
    "    ppg_quality_stream = data._data.groupBy(['user','version']+[win]).apply(ppg_quality)\n",
    "    \n",
    "#     ppg_quality_stream.show(10,False)\n",
    "    stream_name = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.quality.all'\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name).set_description(\"Sequence Aligment,Timestamp Correction, Decoding & Quality of MotionsenseHRV\") \\\n",
    "        .add_dataDescriptor(\n",
    "        DataDescriptor().set_name(\"red\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Value of Red LED - PPG\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"infrared\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Value of Infrared LED - PPG\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"green\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Value of Green LED - PPG\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"aclx\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Accelerometer X-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"acly\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Accelerometer Y-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"aclz\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Accelerometer Z-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"gyrox\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Gyroscope X-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"gyroy\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Gyroscope Y-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"gyroz\").set_type(\"float\").set_attribute(\"description\", \\\n",
    "        \"Wrist Gyroscope Z-axis\")) \\\n",
    "        .add_dataDescriptor( \\\n",
    "        DataDescriptor().set_name(\"quality\").set_type(\"integer\").set_attribute(\"description\", \\\n",
    "        \"PPG quality\")) \\\n",
    "        .add_module( \\\n",
    "        ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/motionsenseHRVquality.ipynb\").set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    ppg_quality_stream = DataStream(data=ppg_quality_stream,metadata=stream_metadata)\n",
    "    return ppg_quality_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist = 'left'\n",
    "ppg_stream = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.all'\n",
    "data = CC.get_stream(ppg_stream)\n",
    "users = data.groupBy('user').count().sort('count')\n",
    "all_users = users.toPandas()\n",
    "import pickle\n",
    "pickle.dump(all_users,open('../data/users_mperf.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc3_high_performance/lib/python3.6/site-packages/pyspark/sql/pandas/group_ops.py:76: UserWarning:\n",
      "\n",
      "It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "f2d36ddc-d20e-46c7-974c-fb7fc273db31 done 0\n",
      "784af6b8-2218-4e01-a066-b66eb2832d9d done 1\n",
      "351fbcd3-c1ec-416c-bed7-195fe5d1f41d done 2\n",
      "24e24816-b56b-4c16-9e6d-0ae8afc8650f done 3\n",
      "af8c78cf-7d82-44f0-a277-abe61896b015 done 4\n",
      "26eeb04e-ab64-45b2-bb12-7aff7a779f9a done 5\n",
      "58e04a3a-1f6d-453c-9250-5b218ba2e99c done 6\n",
      "f16d63b1-c63a-42e0-80c9-aa18ec513da3 done 7\n",
      "ec7bb904-196c-4040-997e-d5e23ad1a553 done 8\n",
      "6b74bbc2-128a-4206-82e1-eaec79579c51 done 9\n",
      "3b6fda64-bb3f-4a77-bec0-7ba034d4540e done 10\n",
      "1b46a6a9-0e7d-4740-b101-b5bc28154f2c done 11\n",
      "efc3b444-ae8b-4106-8cfe-689e0cb4dbb9 done 12\n",
      "3b4966d8-f38a-46cc-ba12-4f059b753241 done 13\n",
      "6cd16a05-3496-4c8e-a915-b44ac950e241 done 14\n",
      "f1a772e9-bf5f-4bc9-96ea-7a45f38c8c41 done 15\n",
      "c9b4e8d8-34f7-474b-9233-db1d945d8fa0 done 16\n",
      "95a070a7-086b-4f3d-a5ba-0a877f7fabf7 done 17\n",
      "e1af82ce-6892-4ecf-9f88-be2dd624c100 done 18\n",
      "1b524925-07d8-42ea-8876-ada7298369ec done 19\n",
      "b4b75916-a561-41e4-b3b9-5dfc2859028d done 20\n",
      "8b73cf24-6579-4a9f-b7db-62317feb4d58 done 21\n",
      "c81cafe4-2589-4207-b8ba-6abbc2e311c2 done 22\n",
      "34223626-fab9-48f5-82bd-0b0037745994 done 23\n",
      "5aeb56d6-af68-4189-a8ec-1f8d8a0c9e02 done 24\n",
      "41bf78e2-4791-4d2e-9459-22f401074964 done 25\n",
      "6676c0e9-c6a6-413e-8355-fea361685385 done 26\n",
      "63684250-6bd1-41e6-b270-ebfc5379a271 done 27\n",
      "6f157d6b-d974-4ec4-9c93-7e29bdaf0108 done 28\n",
      "862ab494-446d-43f6-b752-af51e938547e done 29\n",
      "9b428196-6991-4ddf-b3eb-62009dc722db done 30\n",
      "2f256f48-8336-4846-9362-7349ae648dc5 done 31\n",
      "ee179373-c30e-4ef2-9f32-75419e005cf4 done 32\n",
      "de5c2828-29c5-4545-8367-502bb0ed1004 done 33\n",
      "e0807204-0086-4287-8ca4-6bff1759202c done 34\n",
      "80134e57-9f6a-42e6-bd13-01875b5af715 done 35\n",
      "7d42a964-9a59-4014-b3c7-49b65ce94d04 done 36\n",
      "ea8ee8f7-b950-4cbb-95f7-c87da15d3e82 done 37\n",
      "326a6c55-c963-42c2-bb8a-2591993aaaa2 done 38\n",
      "3f38d579-66fa-4126-b269-3f4e1ee42b39 done 39\n",
      "a5e9c6b1-40b2-4763-862b-61811f58f2cb done 40\n",
      "5cd4f692-3b13-4728-9df3-debc682e42dd done 41\n",
      "038aafca-cc30-47c6-9cbe-5c2cb52d8f04 done 42\n",
      "805f3a7b-a197-4834-a4e4-a56da3dde6b1 done 43\n",
      "08149a8b-8b77-45b6-b092-c9049f9e0214 done 44\n",
      "b39f9f83-5621-4a30-b6e1-1f21acd3b7c8 done 45\n",
      "4c8cf704-9adc-4c01-ab25-3addbd69c308 done 46\n",
      "3c77a951-188c-4c57-93b0-b7a194d4cc19 done 47\n",
      "247d42cf-f81c-44d2-9db8-fea69f468d58 done 48\n",
      "c2ad5056-c319-4b12-8e04-f6d63f61859f done 49\n",
      "d609008d-6efb-4cd0-ab84-6c0de55198db done 50\n",
      "0990887a-6163-4c80-9c9e-468ea2598202 done 51\n",
      "b61ebedd-272f-4276-9eee-63bb9e1a4ad6 done 52\n",
      "82d8787f-ed86-41a0-b342-451c6064dc59 done 53\n",
      "37733a30-f84c-416d-977f-ac3a5b2a68c4 done 54\n",
      "17b79ee0-4d3c-44ac-bfea-90b1f0540d4b done 55\n",
      "74fd99d6-7bfc-40ae-b90f-1639c79294d3 done 56\n",
      "31d42f9e-627c-489a-9c24-4513af7c7511 done 57\n",
      "2d954abb-e11a-4f25-8f12-19a210c8d8e1 done 58\n",
      "9f5be69d-028c-4020-8140-439e652e2343 done 59\n",
      "948b8d17-35af-40cc-aa50-70a12b56e433 done 60\n",
      "a7ce0aa3-aec1-4a46-b6f9-8073fb1e23f1 done 61\n",
      "a28665d0-c10f-4f3e-946a-2b37b8799621 done 62\n",
      "dc2207d1-98d4-47e2-b38d-5bee12e217e2 done 63\n",
      "589461d6-9956-4c9e-820e-a564a93a298b done 64\n",
      "1babaec3-2adb-4812-a377-c0a759a1f624 done 65\n",
      "c7091bfb-1ab2-4fbe-9d09-ae801a2585a2 done 66\n",
      "d4505c6f-2bf5-4aba-8946-5923118c96ce done 67\n",
      "8706b3fe-76f7-49a9-921f-d81577e9511c done 68\n",
      "af533808-e79f-4f2b-994b-969dcf0e4f5d done 69\n",
      "e44afc25-08b9-432e-ba89-7f0fc80b95cf done 70\n",
      "077ff26a-4f7b-48d2-833e-1b9d31cb7615 done 71\n",
      "53b45c45-9ca0-4ec9-b54d-90ffdfec0c38 done 72\n",
      "40556c24-113c-49f9-9371-34931d4fba2d done 73\n",
      "3de8cf32-173f-4514-b9f7-91503d14dafc done 74\n",
      "20a07a1c-ee7e-4958-a2c8-0db6e4fe0ce9 done 75\n",
      "d76db16a-b758-4094-8bfe-4f7167555b73 done 76\n",
      "682564cb-62be-40ff-b5f6-0f53924d37e3 done 77\n",
      "c508e151-eef0-419c-9cb4-e7b1c3337873 done 78\n",
      "b7932ae0-7abb-4fee-b70f-1f6fa5835fcc done 79\n",
      "8861a2f4-80be-4c62-8c1e-252efad26ccc done 80\n",
      "b4dfa455-19e0-4323-96cc-1801e9721b08 done 81\n",
      "b8bbd940-ba64-474c-bfea-37e578fc2133 done 82\n",
      "bb23dbbc-b679-4849-b1d8-63279cad50e2 done 83\n",
      "2eb6842a-1240-43d3-9fdb-954a614411a9 done 84\n",
      "ded067ce-6c9a-4b7d-93ca-b848b6977d45 done 85\n",
      "cb8a3787-1e23-4265-bf3d-264bfe6b25e8 done 86\n",
      "2648558c-0040-427f-8f7e-50e78b24107e done 87\n",
      "3b9ff2e4-dfec-4022-8994-1a0c4db7227a done 88\n",
      "c5677eca-f00e-45af-ab0c-7388438c85e3 done 89\n",
      "157022dd-d527-460d-8abc-dca2f3310394 done 90\n",
      "4d7d8db6-d135-4db5-a718-11582822ff1a done 91\n",
      "feaad88c-c9f0-405a-a32f-4c9adfc0be6b done 92\n",
      "94eb0755-56a3-4235-b759-8dc2ced70875 done 93\n",
      "34521ae7-012a-400f-8794-3d76ff4e70ab done 94\n",
      "61d1a237-d70f-49b0-89ba-cea4d2526832 done 95\n",
      "c696b0e8-299f-4270-9218-25f973bc64b4 done 96\n"
     ]
    }
   ],
   "source": [
    "users = pickle.load(open('../data/users_mperf.p','rb'))\n",
    "wrist = 'left'\n",
    "ppg_stream = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.all'\n",
    "check = False\n",
    "for i,user in enumerate(users['user']):\n",
    "    try:\n",
    "        data = CC.get_stream(ppg_stream,user_id=user)\n",
    "        data_quality = dc_quality_motionsensehrv(data,wrist='left')\n",
    "        if not check:\n",
    "            CC.save_stream(data_quality,overwrite=True)\n",
    "            print(i)\n",
    "            check = True\n",
    "        else:\n",
    "            CC.save_stream(data_quality,overwrite=False)\n",
    "        print(user,'done',i)\n",
    "    except Exception as e:\n",
    "        print('error',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist = 'left'\n",
    "ppg_stream = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.all'\n",
    "data = CC.get_stream(ppg_stream)\n",
    "data_quality = dc_quality_motionsensehrv(data,wrist='left')\n",
    "CC.save_stream(data_quality,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandpass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType, StringType, TimestampType, IntegerType\n",
    "import numpy as np\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "    ModuleMetadata\n",
    "from scipy import signal\n",
    "def filter_data(X,\n",
    "                Fs=25,\n",
    "                low_cutoff=.4,\n",
    "                high_cutoff=3.0,\n",
    "                filter_order=65):\n",
    "    \"\"\"\n",
    "    Bandpass Filter of single channel\n",
    "\n",
    "    :param X: input data\n",
    "    :param Fs: sampling freq.\n",
    "    :param low_cutoff: low passband\n",
    "    :param high_cutoff: high passband\n",
    "    :param filter_order: no of taps in FIR filter\n",
    "\n",
    "    :return: filtered version of input data\n",
    "    \"\"\"\n",
    "    X1 = X.reshape(-1,1)\n",
    "    X1 = signal.detrend(X1,axis=0,type='constant')\n",
    "    b = signal.firls(filter_order,np.array([0,low_cutoff-.1, low_cutoff, high_cutoff ,high_cutoff+.5,Fs/2]),np.array([0, 0 ,1 ,1 ,0, 0]),\n",
    "                     np.array([100*0.02,0.02,0.02]),fs=Fs)\n",
    "    X2 = signal.convolve(X1.reshape(-1),b,mode='same')\n",
    "    return X2\n",
    "\n",
    "def get_metadata(data,\n",
    "                 wrist='left',\n",
    "                 sensor_name='motionsensehrv',\n",
    "                 ppg_columns=('red','infrared','green'),\n",
    "                 acl_columns=('aclx','acly','aclz')):\n",
    "    \"\"\"\n",
    "    :param data: input stream\n",
    "    :param wrist: which wrist the data was collected from\n",
    "    :param sensor_name: name of sensor\n",
    "    :param ppg_columns: columns in the input dataframe referring to multiple ppg channels\n",
    "    :param acl_columns: columns in the input dataframe referring to accelerometer channels\n",
    "\n",
    "    :return: metadata of output stream\n",
    "    \"\"\"\n",
    "    stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.bandpass.filtered\"\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name).set_description(\"Bandpass Filtered PPG data\") \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"timestamp\").set_type(\"datetime\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"localtime\").set_type(\"datetime\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"version\").set_type(\"int\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"user\").set_type(\"string\"))\n",
    "\n",
    "    for c in ppg_columns:\n",
    "        stream_metadata.add_dataDescriptor(DataDescriptor().set_name(c).set_type(\"double\").set_attribute(\"description\",\n",
    "                                                                                                    \"ppg channel \"+c))\n",
    "    for c in acl_columns:\n",
    "        stream_metadata.add_dataDescriptor(DataDescriptor().set_name(c).set_type(\"double\").set_attribute(\"description\",\n",
    "                                                                                            \"accelerometer channel \"+c))\n",
    "\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"ecg data quality\").set_attribute(\"url\", \"http://md2k.org/\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    return stream_metadata\n",
    "\n",
    "\n",
    "def bandpass_filter(\n",
    "                   data,\n",
    "                   Fs = 25,\n",
    "                   low_cutoff = 0.4,\n",
    "                   high_cutoff = 3.0,\n",
    "                   filter_order = 65,\n",
    "                   ppg_columns=('red','infrared','green'),\n",
    "                   acl_columns=('aclx','acly','aclz'),\n",
    "                   wrist='left',\n",
    "                   sensor_name='motionsensehrv'):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    :param data: PPG & ACL data stream\n",
    "    :param Fs: sampling frequency\n",
    "    :param low_cutoff: minimum frequency of pass band\n",
    "    :param high_cutoff: Maximum Frequency of pass band\n",
    "    :param filter_order: no. of taps in FIR filter\n",
    "    :param ppg_columns: columns in the input dataframe referring to multiple ppg channels\n",
    "    :param acl_columns: columns in the input dataframe referring to accelerometer channels\n",
    "    :param wrist: which wrist the data was collected from\n",
    "    :param sensor_name: name of sensor\n",
    "\n",
    "    :return: Bandpass filtered version of input PPG data\n",
    "    \"\"\"\n",
    "\n",
    "    ## check if all columns exist\n",
    "\n",
    "    default_columns = ['user','version','localtime','timestamp']\n",
    "    required_columns = default_columns+acl_columns+ppg_columns\n",
    "    if len(set(required_columns)-set(data.columns))>0:\n",
    "        raise Exception(\"Columns missing in input dataframe! \" + str(list(set(required_columns)-set(data.columns))))\n",
    "\n",
    "    ## select the columns from input dataframe\n",
    "\n",
    "    data = data.select(*required_columns)\n",
    "\n",
    "    ## udf\n",
    "\n",
    "    default_schema = [StructField(\"timestamp\", TimestampType()),\n",
    "                      StructField(\"localtime\", TimestampType()),\n",
    "                      StructField(\"version\", IntegerType()),\n",
    "                      StructField(\"user\", StringType())]\n",
    "    schema = StructType(default_schema+[StructField(c, DoubleType()) for c in list(ppg_columns)+list(acl_columns)])\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def ppg_bandpass(data):\n",
    "        if data.shape[0]<1000:\n",
    "            return pd.DataFrame([],columns=data.columns)\n",
    "        data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "        for c in ppg_columns:\n",
    "            data[c] = filter_data(data[c].values,Fs=Fs,low_cutoff=low_cutoff,high_cutoff=high_cutoff,filter_order=filter_order)\n",
    "        return data\n",
    "\n",
    "    ## steps\n",
    "    win = F.window(\"timestamp\", windowDuration='3600 seconds', startTime='0 seconds')\n",
    "    ppg_bandpass_filtered = data._data.groupBy(['user','version']+[win]).apply(ppg_bandpass)\n",
    "#     ppg_bandpass_filtered = data.compute(ppg_bandpass,windowDuration=60*60*10,startTime='0 seconds')\n",
    "    output_data = ppg_bandpass_filtered\n",
    "    ds = DataStream(data=output_data,metadata=get_metadata(data,wrist=wrist,sensor_name=sensor_name,\n",
    "                                                           ppg_columns=ppg_columns,acl_columns=acl_columns))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist = 'left'\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.quality.all'\n",
    "data = CC.get_stream(stream_name)\n",
    "data = data.filter(F.col('quality')==0)\n",
    "data  = data.withColumn('day',F.date_format('localtime',\"YYYYMMdd\"))\n",
    "filtered_data = bandpass_filter(\n",
    "                   data,\n",
    "                   Fs = 25,\n",
    "                   low_cutoff = 0.4,\n",
    "                   high_cutoff = 4.0,\n",
    "                   filter_order = 65,\n",
    "                   ppg_columns=['red','green','infrared'],\n",
    "                   acl_columns=['aclx','acly','aclz'],\n",
    "                   wrist=wrist,\n",
    "                   sensor_name='motionsensehrvmperf')\n",
    "CC.save_stream(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Minute Length Data by Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata1(data,\n",
    "                 wrist,\n",
    "                 sensor_name='motionsensehrvmperf',\n",
    "                 ppg_columns=('red','infrared','green'),\n",
    "                 acl_columns=('aclx','acly','aclz'),\n",
    "                 gyro_columns=('gyrox','gyroy','gyroz')):\n",
    "    \"\"\"\n",
    "    :param data: input stream\n",
    "    :param wrist: which wrist the data was collected from\n",
    "    :param sensor_name: name of sensor\n",
    "    :param ppg_columns: columns in the input dataframe referring to multiple ppg channels\n",
    "    :param acl_columns: columns in the input dataframe referring to accelerometer channels\n",
    "\n",
    "    :return: metadata of output stream\n",
    "    \"\"\"\n",
    "    stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.acl.filtered\"\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name).set_description(\"Bandpass Filtered PPG data\") \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"timestamp\").set_type(\"datetime\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"localtime\").set_type(\"datetime\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"version\").set_type(\"int\")) \\\n",
    "        .add_dataDescriptor(DataDescriptor().set_name(\"user\").set_type(\"string\"))\n",
    "\n",
    "    for c in ppg_columns:\n",
    "        stream_metadata.add_dataDescriptor(DataDescriptor().set_name(c).set_type(\"double\").set_attribute(\"description\",\n",
    "                                                                                                    \"ppg channel \"+c))\n",
    "    for c in acl_columns:\n",
    "        stream_metadata.add_dataDescriptor(DataDescriptor().set_name(c).set_type(\"double\").set_attribute(\"description\",\n",
    "                                                                                            \"accelerometer channel \"+c))\n",
    "    for c in gyro_columns:\n",
    "        stream_metadata.add_dataDescriptor(DataDescriptor().set_name(c).set_type(\"double\").set_attribute(\"description\",\n",
    "                                                                                            \"gyroscope channel \"+c))\n",
    "\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(\"ppg\").set_attribute(\"url\", \"http://md2k.org/\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    return stream_metadata\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "def filter_60sec_data(data,\n",
    "                      wrist,\n",
    "                      Fs = 25,\n",
    "                      acceptable = .85,\n",
    "                      window_duration = 60):\n",
    "    def get_std(dt):\n",
    "        return np.sqrt(dt['aclx'].std()**2+dt['acly'].std()**2+dt['aclz'].std()**2)\n",
    "    \n",
    "    schema = deepcopy(data.schema)\n",
    "    @pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "    def acl_variance_filter(df):\n",
    "        if df.shape[0]<Fs*acceptable*window_duration:\n",
    "            return pd.DataFrame([],columns=df.columns)\n",
    "        df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "#         df['mag'] = df.apply(lambda a:np.sqrt(a['aclx']**2+a['acly']**2+a['aclz']**2),axis=1)\n",
    "        acl_stds = np.array([get_std(d) for i,d in df.groupby(pd.Grouper(key='timestamp',freq='5S'))])\n",
    "#         variance = np.sqrt(np.square(df['aclx'].std())+np.square(df['acly'].std())+np.square(df['aclz'].std()))\n",
    "#         variance = len(acl_stds[acl_stds>=.21])<=len(acl_stds)*.5 \n",
    "#         df.drop(columns=['mag'],inplace=True) \n",
    "        if np.median(acl_stds)<.21:\n",
    "            return pd.DataFrame([],columns=df.columns)\n",
    "        else:\n",
    "            print('-'*40,'This works')\n",
    "            return df\n",
    "    win = F.window(\"timestamp\", windowDuration='60 seconds', startTime='0 seconds')\n",
    "    ppg_filtered = data._data.groupBy(['user','version']+[win]).apply(acl_variance_filter)\n",
    "    metadata1 = get_metadata1(data,wrist=wrist)\n",
    "    ds = DataStream(data=ppg_filtered,metadata=metadata1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wrist = 'left'\n",
    "stream_name = 'org.md2k.feature.motionsensehrv.decoded.'+str(wrist)+'wrist.quality.all'\n",
    "data = CC.get_stream(stream_name)\n",
    "data = data.filter(F.col('quality')==0).drop('quality')\n",
    "ds = filter_60sec_data(data,wrist=wrist)\n",
    "CC.save_stream(ds,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Data Proportions by participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrist = 'left'\n",
    "sensor_name='motionsensehrvmperf'\n",
    "stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.acl.filtered\"\n",
    "data = CC.get_stream(stream_name)\n",
    "data  = data.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "\n",
    "count_data = data._data.groupBy(['user','day']).count().toPandas()\n",
    "count_data['count'] = count_data['count']/(25*3600)\n",
    "data_users = count_data.groupby('user',as_index=False).count()\n",
    "data_users = data_users[data_users['count']>10]\n",
    "users_wanted = data_users['user'].values\n",
    "count_data_final = count_data[count_data.user.isin(users_wanted)&count_data['count']>.5]\n",
    "\n",
    "total_user_data = count_data_final.groupby(['user']).sum().to_dict()['count']\n",
    "\n",
    "daywise_user_data = count_data_final.groupby(['user','day']).sum().to_dict()['count']\n",
    "\n",
    "pickle.dump([total_user_data,daywise_user_data],open('../data/data_participants.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_data,daywise_user_data = pickle.load(open('../data/data_participants.p','rb'))\n",
    "wrist = 'left'\n",
    "sensor_name='motionsensehrvmperf'\n",
    "stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.acl.filtered\"\n",
    "data = CC.get_stream(stream_name)\n",
    "users = list(total_user_data.keys())\n",
    "data = data.filter(F.col('user').isin(users))\n",
    "data  = data.withColumn('day',F.date_format('localtime',\"yyyyMMdd\"))\n",
    "days = list(list(zip(*list(daywise_user_data.keys())))[1])\n",
    "data = data.filter(F.col('day').isin(days))\n",
    "\n",
    "data = data.withColumn('time',F.col('timestamp').cast('double'))\n",
    "\n",
    "data = data.withColumn('data',F.array('time',\n",
    "                                      'red','infrared','green',\n",
    "                                      'aclx','acly','aclz',\n",
    "                                      'gyrox','gyroy','gyroz')).drop(*['time','red','infrared','green','aclx',\n",
    "                                                       'acly','aclz','gyrox','gyroy','gyroz'])\n",
    "\n",
    "win = F.window(\"timestamp\", windowDuration='60 seconds', startTime='0 seconds')\n",
    "groupbycols = [\"user\",'version'] + [win]\n",
    "data_grouped = data._data.groupBy(groupbycols).agg(F.collect_list('data'),\n",
    "                                                   F.collect_list('timestamp'),\n",
    "                                                  F.collect_list('localtime')).withColumnRenamed('collect_list(data)',\n",
    "                                                                                                 'data').withColumnRenamed('collect_list(timestamp)',\n",
    "                                                                                                                            'timestamp').withColumnRenamed('collect_list(localtime)',\n",
    "                                                                                                                            'localtime')\n",
    "\n",
    "data_grouped = data_grouped.withColumn('localtime',F.col('localtime').getItem(0)).withColumn('timestamp',F.col('timestamp').getItem(0))\n",
    "\n",
    "stream_metadata = Metadata()\n",
    "stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.acl.filtered.data.grouped.minute\"\n",
    "stream_metadata.set_name(stream_name).set_description(\"Data Parsed as minute length array\") \\\n",
    "    .add_dataDescriptor(\n",
    "    DataDescriptor().set_name(\"window\").set_type(\"object\").set_attribute(\"description\", \\\n",
    "    \"start and end times\")) \\\n",
    "    .add_dataDescriptor( \\\n",
    "    DataDescriptor().set_name(\"data\").set_type(\"array\").set_attribute(\"description\", \\\n",
    "    \"input data\")) \\\n",
    "    .add_dataDescriptor( \\\n",
    "    DataDescriptor().set_name(\"user\").set_type(\"string\").set_attribute(\"description\", \\\n",
    "    \"user id\")) \\\n",
    "    .add_dataDescriptor( \\\n",
    "    DataDescriptor().set_name(\"version\").set_type(\"integer\").set_attribute(\"description\", \\\n",
    "    \"version id\")) \\\n",
    "    .add_dataDescriptor( \\\n",
    "    DataDescriptor().set_name(\"timestamp\").set_type(\"timestamp\").set_attribute(\"description\", \\\n",
    "    \"timestamp\")) \\\n",
    "    .add_dataDescriptor( \\\n",
    "    DataDescriptor().set_name(\"localtime\").set_type(\"timestamp\").set_attribute(\"description\", \\\n",
    "    \"localtime\")) \\\n",
    "    .add_module( \\\n",
    "    ModuleMetadata().set_name(\"fourtytwo/mullah/cc3/motionsenseHRVquality.ipynb\").set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "        \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "data_grouped = DataStream(data=data_grouped,metadata=stream_metadata)\n",
    "CC.save_stream(data_grouped,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_name = \"org.md2k.\"+str(sensor_name)+\".\"+str(wrist)+\".wrist.acl.filtered.data.grouped.minute\"\n",
    "data = CC.get_stream(stream_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "323953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3 High Performance",
   "language": "python",
   "name": "cc3_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
