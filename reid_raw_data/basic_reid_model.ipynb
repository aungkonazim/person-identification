{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "opponent-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "average-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y_hr,y_participant,y_activity,y_time = pickle.load(open('../data/dalia_individual_windows.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "exotic-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_val_data(X_hr,y_participant,y_time,y_activity):\n",
    "    all_data = pd.DataFrame({'x':np.arange(X_hr.shape[0]),'y':y_participant,'time':y_time,'activity':y_activity})\n",
    "    train_percentage = .6\n",
    "    val_percentage = train_percentage+.1\n",
    "    def split_data(df):\n",
    "        df = df.sort_values('time').reset_index(drop=True)\n",
    "        n = df.shape[0]\n",
    "        train_index = df['x'].values[:int(n*train_percentage)]\n",
    "        val_index = df['x'].values[int(n*train_percentage):int(n*val_percentage)]\n",
    "        test_index = df['x'].values[int(n*val_percentage):]\n",
    "        return pd.DataFrame({'train':[list(train_index)],'val':[list(val_index)],'test':[list(test_index)]})\n",
    "\n",
    "    index_df = all_data.groupby(['y','activity'],as_index=False).apply(split_data)\n",
    "\n",
    "    from functools import reduce\n",
    "    train_index = np.array(reduce(lambda a,b:a+b,index_df['train'].values))\n",
    "    val_index = np.array(reduce(lambda a,b:a+b,index_df['val'].values))\n",
    "    test_index = np.array(reduce(lambda a,b:a+b,index_df['test'].values))\n",
    "\n",
    "\n",
    "    train_x,train_y = X_hr[train_index],y_participant[train_index]\n",
    "    val_x,val_y = X_hr[val_index],y_participant[val_index]\n",
    "    test_x,test_y = X_hr[test_index],y_participant[test_index]\n",
    "    return train_x,train_y,val_x,val_y,test_x,test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "rational-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 256\n",
    "n_channels = 4\n",
    "train_x,train_y,val_x,val_y,test_x,test_y = get_train_test_val_data(X[:,:,:n_channels],y_participant,y_time,y_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "furnished-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,LeaveOneGroupOut,LeavePGroupsOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from keras.layers import Conv1D,Reshape,BatchNormalization,TimeDistributed, \\\n",
    "Dropout,Input,MaxPooling1D,Flatten,Dense,Input, GaussianNoise,LSTM, Bidirectional, Input,GRU\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer,LabelEncoder\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "mathematical-spirituality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 256, 1)]          0         \n",
      "_________________________________________________________________\n",
      "sequential_14 (Sequential)   (None, 15)                336665    \n",
      "_________________________________________________________________\n",
      "feature (Lambda)             (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 15)                240       \n",
      "=================================================================\n",
      "Total params: 336,905\n",
      "Trainable params: 336,305\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_shape=(256,4),act='relu',loss=\"categorical_crossentropy\",opt='adam',\n",
    "              n_classes=350,n_output = 15):\n",
    "    \n",
    "    \n",
    "    model =  Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Reshape(input_shape))\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='selu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(Conv1D(100,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "#     model.add(Bidirectional(GRU(10,activation='relu',return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.2))\n",
    "    model.add(Conv1D(100,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "#     model.add(Bidirectional(GRU(10,activation='relu',return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(.2))\n",
    "    model.add(Conv1D(100,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "#     model.add(Bidirectional(GRU(10,activation='relu',return_sequences=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(50,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "#     model.add(Bidirectional(GRU(10,activation='relu',return_sequences=True)))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_output,activation=None))\n",
    "    \n",
    "    input_ = Input(shape=input_shape)\n",
    "    embedding = model(input_)\n",
    "    final_embedding = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1),name='feature')(embedding)\n",
    "    \n",
    "#     class_embedding = Dense(n_output,activation='sigmoid')(final_embedding)\n",
    "    y_output = Dense(n_output,activation='softmax',name='output')(final_embedding) \n",
    "    model1 = Model(input_,[y_output,final_embedding])\n",
    "    model1.compile(loss={'output':tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                        'feature':tfa.losses.TripletSemiHardLoss()},optimizer=opt,\n",
    "                   loss_weights={'output':1,'feature':1})\n",
    "    return model1\n",
    "\n",
    "model1 = get_model(input_shape=(n_timesteps,1))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "human-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 256, 4)]          0         \n",
      "_________________________________________________________________\n",
      "sequential_15 (Sequential)   (None, 15)                339665    \n",
      "_________________________________________________________________\n",
      "feature (Lambda)             (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 15)                240       \n",
      "=================================================================\n",
      "Total params: 339,905\n",
      "Trainable params: 339,305\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 3.4593 - output_loss: 2.4633 - feature_loss: 0.9960\n",
      "Epoch 00001: val_loss improved from inf to 3.69266, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 3.4591 - output_loss: 2.4631 - feature_loss: 0.9959 - val_loss: 3.6927 - val_output_loss: 2.6984 - val_feature_loss: 0.9942\n",
      "Epoch 2/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 3.3028 - output_loss: 2.3083 - feature_loss: 0.9945\n",
      "Epoch 00002: val_loss improved from 3.69266 to 3.48826, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 3.3027 - output_loss: 2.3083 - feature_loss: 0.9944 - val_loss: 3.4883 - val_output_loss: 2.5005 - val_feature_loss: 0.9877\n",
      "Epoch 3/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 3.1889 - output_loss: 2.1956 - feature_loss: 0.9932\n",
      "Epoch 00003: val_loss improved from 3.48826 to 3.31990, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 3.1888 - output_loss: 2.1957 - feature_loss: 0.9931 - val_loss: 3.3199 - val_output_loss: 2.3400 - val_feature_loss: 0.9799\n",
      "Epoch 4/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 3.0976 - output_loss: 2.1055 - feature_loss: 0.9921\n",
      "Epoch 00004: val_loss improved from 3.31990 to 3.16260, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 3.0974 - output_loss: 2.1054 - feature_loss: 0.9920 - val_loss: 3.1626 - val_output_loss: 2.1903 - val_feature_loss: 0.9723\n",
      "Epoch 5/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 3.0030 - output_loss: 2.0123 - feature_loss: 0.9908\n",
      "Epoch 00005: val_loss improved from 3.16260 to 3.09190, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 3.0028 - output_loss: 2.0122 - feature_loss: 0.9906 - val_loss: 3.0919 - val_output_loss: 2.1193 - val_feature_loss: 0.9726\n",
      "Epoch 6/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.9097 - output_loss: 1.9201 - feature_loss: 0.9896\n",
      "Epoch 00006: val_loss improved from 3.09190 to 2.97609, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 114ms/step - loss: 2.9094 - output_loss: 1.9199 - feature_loss: 0.9895 - val_loss: 2.9761 - val_output_loss: 2.0175 - val_feature_loss: 0.9586\n",
      "Epoch 7/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.8108 - output_loss: 1.8234 - feature_loss: 0.9874\n",
      "Epoch 00007: val_loss improved from 2.97609 to 2.93547, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 5s 115ms/step - loss: 2.8105 - output_loss: 1.8232 - feature_loss: 0.9873 - val_loss: 2.9355 - val_output_loss: 1.9703 - val_feature_loss: 0.9652\n",
      "Epoch 8/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.7140 - output_loss: 1.7283 - feature_loss: 0.9857\n",
      "Epoch 00008: val_loss improved from 2.93547 to 2.88100, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 115ms/step - loss: 2.7138 - output_loss: 1.7282 - feature_loss: 0.9856 - val_loss: 2.8810 - val_output_loss: 1.9238 - val_feature_loss: 0.9572\n",
      "Epoch 9/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.6161 - output_loss: 1.6329 - feature_loss: 0.9832\n",
      "Epoch 00009: val_loss improved from 2.88100 to 2.84508, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 115ms/step - loss: 2.6162 - output_loss: 1.6331 - feature_loss: 0.9831 - val_loss: 2.8451 - val_output_loss: 1.8885 - val_feature_loss: 0.9566\n",
      "Epoch 10/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.5100 - output_loss: 1.5309 - feature_loss: 0.9792\n",
      "Epoch 00010: val_loss improved from 2.84508 to 2.83909, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 115ms/step - loss: 2.5095 - output_loss: 1.5306 - feature_loss: 0.9790 - val_loss: 2.8391 - val_output_loss: 1.8726 - val_feature_loss: 0.9664\n",
      "Epoch 11/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.4125 - output_loss: 1.4375 - feature_loss: 0.9751\n",
      "Epoch 00011: val_loss improved from 2.83909 to 2.75376, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 115ms/step - loss: 2.4122 - output_loss: 1.4374 - feature_loss: 0.9748 - val_loss: 2.7538 - val_output_loss: 1.8037 - val_feature_loss: 0.9501\n",
      "Epoch 12/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.3035 - output_loss: 1.3339 - feature_loss: 0.9696\n",
      "Epoch 00012: val_loss improved from 2.75376 to 2.66785, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 2.3031 - output_loss: 1.3337 - feature_loss: 0.9694 - val_loss: 2.6679 - val_output_loss: 1.7247 - val_feature_loss: 0.9432\n",
      "Epoch 13/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.1951 - output_loss: 1.2324 - feature_loss: 0.9627\n",
      "Epoch 00013: val_loss did not improve from 2.66785\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 2.1950 - output_loss: 1.2325 - feature_loss: 0.9625 - val_loss: 2.6859 - val_output_loss: 1.7298 - val_feature_loss: 0.9561\n",
      "Epoch 14/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.1085 - output_loss: 1.1534 - feature_loss: 0.9551\n",
      "Epoch 00014: val_loss did not improve from 2.66785\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 2.1082 - output_loss: 1.1533 - feature_loss: 0.9549 - val_loss: 2.7227 - val_output_loss: 1.7742 - val_feature_loss: 0.9484\n",
      "Epoch 15/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 2.0102 - output_loss: 1.0632 - feature_loss: 0.9470\n",
      "Epoch 00015: val_loss did not improve from 2.66785\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 2.0097 - output_loss: 1.0629 - feature_loss: 0.9468 - val_loss: 2.7248 - val_output_loss: 1.7654 - val_feature_loss: 0.9594\n",
      "Epoch 16/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.9198 - output_loss: 0.9835 - feature_loss: 0.9363\n",
      "Epoch 00016: val_loss improved from 2.66785 to 2.55879, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.9197 - output_loss: 0.9836 - feature_loss: 0.9361 - val_loss: 2.5588 - val_output_loss: 1.6140 - val_feature_loss: 0.9448\n",
      "Epoch 17/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.8062 - output_loss: 0.8859 - feature_loss: 0.9203\n",
      "Epoch 00017: val_loss did not improve from 2.55879\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 1.8056 - output_loss: 0.8857 - feature_loss: 0.9199 - val_loss: 2.5663 - val_output_loss: 1.6247 - val_feature_loss: 0.9416\n",
      "Epoch 18/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.7414 - output_loss: 0.8281 - feature_loss: 0.9133\n",
      "Epoch 00018: val_loss improved from 2.55879 to 2.54096, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.7411 - output_loss: 0.8282 - feature_loss: 0.9129 - val_loss: 2.5410 - val_output_loss: 1.5895 - val_feature_loss: 0.9514\n",
      "Epoch 19/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.6613 - output_loss: 0.7619 - feature_loss: 0.8994\n",
      "Epoch 00019: val_loss did not improve from 2.54096\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.6609 - output_loss: 0.7619 - feature_loss: 0.8990 - val_loss: 2.5578 - val_output_loss: 1.6097 - val_feature_loss: 0.9481\n",
      "Epoch 20/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.5884 - output_loss: 0.7016 - feature_loss: 0.8867\n",
      "Epoch 00020: val_loss did not improve from 2.54096\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.5881 - output_loss: 0.7017 - feature_loss: 0.8864 - val_loss: 2.5971 - val_output_loss: 1.6450 - val_feature_loss: 0.9521\n",
      "Epoch 21/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.5054 - output_loss: 0.6372 - feature_loss: 0.8683\n",
      "Epoch 00021: val_loss improved from 2.54096 to 2.49466, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.5050 - output_loss: 0.6371 - feature_loss: 0.8679 - val_loss: 2.4947 - val_output_loss: 1.5512 - val_feature_loss: 0.9435\n",
      "Epoch 22/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.4442 - output_loss: 0.5892 - feature_loss: 0.8550\n",
      "Epoch 00022: val_loss did not improve from 2.49466\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.4439 - output_loss: 0.5892 - feature_loss: 0.8547 - val_loss: 2.5095 - val_output_loss: 1.5579 - val_feature_loss: 0.9516\n",
      "Epoch 23/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.3703 - output_loss: 0.5362 - feature_loss: 0.8341\n",
      "Epoch 00023: val_loss improved from 2.49466 to 2.49034, saving model to ../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.3696 - output_loss: 0.5360 - feature_loss: 0.8336 - val_loss: 2.4903 - val_output_loss: 1.5428 - val_feature_loss: 0.9476\n",
      "Epoch 24/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.3026 - output_loss: 0.4861 - feature_loss: 0.8165\n",
      "Epoch 00024: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.3029 - output_loss: 0.4864 - feature_loss: 0.8165 - val_loss: 2.5994 - val_output_loss: 1.6497 - val_feature_loss: 0.9497\n",
      "Epoch 25/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.2722 - output_loss: 0.4598 - feature_loss: 0.8124\n",
      "Epoch 00025: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.2718 - output_loss: 0.4597 - feature_loss: 0.8121 - val_loss: 2.5119 - val_output_loss: 1.5689 - val_feature_loss: 0.9431\n",
      "Epoch 26/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.2136 - output_loss: 0.4202 - feature_loss: 0.7934\n",
      "Epoch 00026: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.2132 - output_loss: 0.4201 - feature_loss: 0.7931 - val_loss: 2.5471 - val_output_loss: 1.6026 - val_feature_loss: 0.9445\n",
      "Epoch 27/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.1735 - output_loss: 0.3890 - feature_loss: 0.7844\n",
      "Epoch 00027: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 1.1733 - output_loss: 0.3890 - feature_loss: 0.7842 - val_loss: 2.5594 - val_output_loss: 1.6091 - val_feature_loss: 0.9503\n",
      "Epoch 28/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.1173 - output_loss: 0.3542 - feature_loss: 0.7631\n",
      "Epoch 00028: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.1168 - output_loss: 0.3542 - feature_loss: 0.7626 - val_loss: 2.5150 - val_output_loss: 1.5779 - val_feature_loss: 0.9371\n",
      "Epoch 29/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.0831 - output_loss: 0.3297 - feature_loss: 0.7533\n",
      "Epoch 00029: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.0825 - output_loss: 0.3296 - feature_loss: 0.7529 - val_loss: 2.5141 - val_output_loss: 1.5686 - val_feature_loss: 0.9454\n",
      "Epoch 30/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.0629 - output_loss: 0.3114 - feature_loss: 0.7515\n",
      "Epoch 00030: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 1.0623 - output_loss: 0.3113 - feature_loss: 0.7510 - val_loss: 2.5875 - val_output_loss: 1.6332 - val_feature_loss: 0.9543\n",
      "Epoch 31/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 1.0347 - output_loss: 0.2922 - feature_loss: 0.7425\n",
      "Epoch 00031: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 1.0341 - output_loss: 0.2921 - feature_loss: 0.7420 - val_loss: 2.6228 - val_output_loss: 1.6715 - val_feature_loss: 0.9513\n",
      "Epoch 32/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.9986 - output_loss: 0.2718 - feature_loss: 0.7268\n",
      "Epoch 00032: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.9979 - output_loss: 0.2717 - feature_loss: 0.7262 - val_loss: 2.5701 - val_output_loss: 1.6259 - val_feature_loss: 0.9442\n",
      "Epoch 33/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.9459 - output_loss: 0.2464 - feature_loss: 0.6996\n",
      "Epoch 00033: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 0.9456 - output_loss: 0.2464 - feature_loss: 0.6992 - val_loss: 2.5597 - val_output_loss: 1.6122 - val_feature_loss: 0.9475\n",
      "Epoch 34/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.9238 - output_loss: 0.2312 - feature_loss: 0.6926\n",
      "Epoch 00034: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.9232 - output_loss: 0.2312 - feature_loss: 0.6920 - val_loss: 2.5405 - val_output_loss: 1.6089 - val_feature_loss: 0.9315\n",
      "Epoch 35/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.9140 - output_loss: 0.2227 - feature_loss: 0.6912\n",
      "Epoch 00035: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.9133 - output_loss: 0.2226 - feature_loss: 0.6907 - val_loss: 2.6096 - val_output_loss: 1.6756 - val_feature_loss: 0.9341\n",
      "Epoch 36/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.8830 - output_loss: 0.2063 - feature_loss: 0.6767\n",
      "Epoch 00036: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.8824 - output_loss: 0.2063 - feature_loss: 0.6762 - val_loss: 2.6173 - val_output_loss: 1.6842 - val_feature_loss: 0.9330\n",
      "Epoch 37/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.8432 - output_loss: 0.1892 - feature_loss: 0.6540\n",
      "Epoch 00037: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.8434 - output_loss: 0.1894 - feature_loss: 0.6540 - val_loss: 2.5667 - val_output_loss: 1.6345 - val_feature_loss: 0.9322\n",
      "Epoch 38/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.8534 - output_loss: 0.1890 - feature_loss: 0.6644\n",
      "Epoch 00038: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 0.8533 - output_loss: 0.1891 - feature_loss: 0.6642 - val_loss: 2.5923 - val_output_loss: 1.6511 - val_feature_loss: 0.9411\n",
      "Epoch 39/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.8289 - output_loss: 0.1767 - feature_loss: 0.6523\n",
      "Epoch 00039: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.8284 - output_loss: 0.1766 - feature_loss: 0.6518 - val_loss: 2.6727 - val_output_loss: 1.7241 - val_feature_loss: 0.9486\n",
      "Epoch 40/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.7717 - output_loss: 0.1557 - feature_loss: 0.6160\n",
      "Epoch 00040: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.7710 - output_loss: 0.1557 - feature_loss: 0.6154 - val_loss: 2.6333 - val_output_loss: 1.6978 - val_feature_loss: 0.9356\n",
      "Epoch 41/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.8020 - output_loss: 0.1621 - feature_loss: 0.6399\n",
      "Epoch 00041: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.8014 - output_loss: 0.1620 - feature_loss: 0.6394 - val_loss: 2.6456 - val_output_loss: 1.6973 - val_feature_loss: 0.9483\n",
      "Epoch 42/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.7429 - output_loss: 0.1422 - feature_loss: 0.6007\n",
      "Epoch 00042: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.7429 - output_loss: 0.1423 - feature_loss: 0.6006 - val_loss: 2.7015 - val_output_loss: 1.7445 - val_feature_loss: 0.9570\n",
      "Epoch 43/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.7825 - output_loss: 0.1490 - feature_loss: 0.6335\n",
      "Epoch 00043: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.7829 - output_loss: 0.1493 - feature_loss: 0.6336 - val_loss: 2.7290 - val_output_loss: 1.7930 - val_feature_loss: 0.9360\n",
      "Epoch 44/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.7781 - output_loss: 0.1471 - feature_loss: 0.6310\n",
      "Epoch 00044: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.7775 - output_loss: 0.1471 - feature_loss: 0.6304 - val_loss: 2.6981 - val_output_loss: 1.7577 - val_feature_loss: 0.9404\n",
      "Epoch 45/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.7044 - output_loss: 0.1233 - feature_loss: 0.5810\n",
      "Epoch 00045: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.7043 - output_loss: 0.1235 - feature_loss: 0.5809 - val_loss: 2.7096 - val_output_loss: 1.7805 - val_feature_loss: 0.9291\n",
      "Epoch 46/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6947 - output_loss: 0.1189 - feature_loss: 0.5758\n",
      "Epoch 00046: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6940 - output_loss: 0.1189 - feature_loss: 0.5750 - val_loss: 2.8065 - val_output_loss: 1.8662 - val_feature_loss: 0.9403\n",
      "Epoch 47/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6996 - output_loss: 0.1174 - feature_loss: 0.5822\n",
      "Epoch 00047: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6989 - output_loss: 0.1174 - feature_loss: 0.5815 - val_loss: 2.7135 - val_output_loss: 1.7945 - val_feature_loss: 0.9190\n",
      "Epoch 48/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6818 - output_loss: 0.1127 - feature_loss: 0.5690\n",
      "Epoch 00048: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 116ms/step - loss: 0.6811 - output_loss: 0.1127 - feature_loss: 0.5684 - val_loss: 2.7047 - val_output_loss: 1.7589 - val_feature_loss: 0.9458\n",
      "Epoch 49/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6538 - output_loss: 0.1039 - feature_loss: 0.5499\n",
      "Epoch 00049: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6535 - output_loss: 0.1039 - feature_loss: 0.5495 - val_loss: 2.8606 - val_output_loss: 1.9409 - val_feature_loss: 0.9197\n",
      "Epoch 50/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6381 - output_loss: 0.0996 - feature_loss: 0.5384\n",
      "Epoch 00050: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6383 - output_loss: 0.1000 - feature_loss: 0.5383 - val_loss: 2.7866 - val_output_loss: 1.8598 - val_feature_loss: 0.9268\n",
      "Epoch 51/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6685 - output_loss: 0.1058 - feature_loss: 0.5627\n",
      "Epoch 00051: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6682 - output_loss: 0.1058 - feature_loss: 0.5624 - val_loss: 2.7944 - val_output_loss: 1.8549 - val_feature_loss: 0.9395\n",
      "Epoch 52/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6586 - output_loss: 0.0994 - feature_loss: 0.5592\n",
      "Epoch 00052: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6581 - output_loss: 0.0994 - feature_loss: 0.5588 - val_loss: 2.8044 - val_output_loss: 1.8783 - val_feature_loss: 0.9261\n",
      "Epoch 53/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6620 - output_loss: 0.1004 - feature_loss: 0.5616\n",
      "Epoch 00053: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.6619 - output_loss: 0.1005 - feature_loss: 0.5614 - val_loss: 2.8413 - val_output_loss: 1.8975 - val_feature_loss: 0.9437\n",
      "Epoch 54/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6407 - output_loss: 0.0942 - feature_loss: 0.5465\n",
      "Epoch 00054: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6407 - output_loss: 0.0943 - feature_loss: 0.5464 - val_loss: 2.8341 - val_output_loss: 1.8935 - val_feature_loss: 0.9406\n",
      "Epoch 55/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6493 - output_loss: 0.0960 - feature_loss: 0.5534\n",
      "Epoch 00055: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6488 - output_loss: 0.0959 - feature_loss: 0.5528 - val_loss: 2.8934 - val_output_loss: 1.9551 - val_feature_loss: 0.9383\n",
      "Epoch 56/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6099 - output_loss: 0.0852 - feature_loss: 0.5246\n",
      "Epoch 00056: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.6092 - output_loss: 0.0852 - feature_loss: 0.5240 - val_loss: 2.8171 - val_output_loss: 1.8855 - val_feature_loss: 0.9316\n",
      "Epoch 57/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.6163 - output_loss: 0.0868 - feature_loss: 0.5296\n",
      "Epoch 00057: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.6163 - output_loss: 0.0868 - feature_loss: 0.5294 - val_loss: 2.8443 - val_output_loss: 1.9037 - val_feature_loss: 0.9406\n",
      "Epoch 58/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5884 - output_loss: 0.0807 - feature_loss: 0.5077\n",
      "Epoch 00058: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.5882 - output_loss: 0.0807 - feature_loss: 0.5075 - val_loss: 2.9050 - val_output_loss: 1.9620 - val_feature_loss: 0.9429\n",
      "Epoch 59/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5670 - output_loss: 0.0746 - feature_loss: 0.4923\n",
      "Epoch 00059: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.5663 - output_loss: 0.0746 - feature_loss: 0.4917 - val_loss: 2.8709 - val_output_loss: 1.9432 - val_feature_loss: 0.9277\n",
      "Epoch 60/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5586 - output_loss: 0.0720 - feature_loss: 0.4866\n",
      "Epoch 00060: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.5579 - output_loss: 0.0721 - feature_loss: 0.4858 - val_loss: 2.9626 - val_output_loss: 2.0299 - val_feature_loss: 0.9327\n",
      "Epoch 61/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5721 - output_loss: 0.0756 - feature_loss: 0.4966\n",
      "Epoch 00061: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.5721 - output_loss: 0.0757 - feature_loss: 0.4964 - val_loss: 2.9431 - val_output_loss: 1.9997 - val_feature_loss: 0.9434\n",
      "Epoch 62/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5664 - output_loss: 0.0738 - feature_loss: 0.4926\n",
      "Epoch 00062: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 118ms/step - loss: 0.5661 - output_loss: 0.0738 - feature_loss: 0.4922 - val_loss: 3.0237 - val_output_loss: 2.0761 - val_feature_loss: 0.9476\n",
      "Epoch 63/400\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5161 - output_loss: 0.0646 - feature_loss: 0.4515\n",
      "Epoch 00063: val_loss did not improve from 2.49034\n",
      "48/48 [==============================] - 6s 117ms/step - loss: 0.5157 - output_loss: 0.0646 - feature_loss: 0.4511 - val_loss: 2.9682 - val_output_loss: 2.0283 - val_feature_loss: 0.9399\n",
      "Epoch 00063: early stopping\n"
     ]
    }
   ],
   "source": [
    "n_classes = 300\n",
    "n_output = len(np.unique(y_participant))\n",
    "model = get_model(input_shape=(n_timesteps,n_channels),n_classes=n_classes,n_output=n_output) \n",
    "model.summary()\n",
    "from keras.models import load_model\n",
    "filepath = '../model_files/base_cnn_60_seconds_raw_ppg_acl_classification.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = model.fit(train_x,[train_y,train_y],validation_data=(val_x,[val_y,val_y]), epochs=400, \n",
    "                    batch_size=600,callbacks=callbacks_list,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "moderate-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "democratic-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)[0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "smaller-aaron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.33      0.35      1055\n",
      "           1       0.44      0.26      0.33       999\n",
      "           2       0.54      0.30      0.38       886\n",
      "           3       0.36      0.44      0.40      1013\n",
      "           4       0.66      0.49      0.56      1075\n",
      "           5       0.58      0.29      0.39       892\n",
      "           6       0.35      0.46      0.40       445\n",
      "           7       0.48      0.37      0.42      1016\n",
      "           8       0.54      0.30      0.38      1070\n",
      "           9       0.50      0.63      0.56      1013\n",
      "          10       0.36      0.56      0.43       987\n",
      "          11       0.47      0.59      0.52       902\n",
      "          12       0.51      0.60      0.55       854\n",
      "          13       0.45      0.34      0.38       964\n",
      "          14       0.30      0.58      0.39      1045\n",
      "\n",
      "    accuracy                           0.44     14216\n",
      "   macro avg       0.46      0.44      0.43     14216\n",
      "weighted avg       0.46      0.44      0.43     14216\n",
      " 0.4351435002813731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y,y_pred),accuracy_score(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-wyoming",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
