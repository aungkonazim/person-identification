{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_acl,X_ppg,y,y_participant,X_time = pickle.load(open('../data/tabular_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,LeaveOneGroupOut,LeavePGroupsOut\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer,LabelEncoder\n",
    "X_ppg = X_ppg[:,np.arange(0,512,2),:]\n",
    "X_all = np.concatenate([X_ppg,X_acl],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43363, 256, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000368052999631947\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "filepath = '../model_files/base_cnn_8_seconds_ppg_acl_wesad.hdf5'\n",
    "index = np.array([0,2,3,4])\n",
    "model = load_model(filepath)\n",
    "\n",
    "def get_windows(pred,time,user,n=30,n_per_user = 100):\n",
    "    df = pd.DataFrame({'time':time,'user':user,'pred':list(pred)})\n",
    "    X = []\n",
    "    y = []\n",
    "    for user in df.user.unique():\n",
    "        for i in range(n_per_user):\n",
    "            X.append(np.array([np.array(a) for a in df[df.user==user]['pred'].sample(n,replace=True).values]).reshape(1,n,13))\n",
    "            y.append(user)\n",
    "    return np.concatenate(X),np.array(y)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "logo = LeavePGroupsOut(n_groups=1)\n",
    "for train_index, test_index in logo.split(X_all, y, y_participant.reshape(-1)):\n",
    "    train_x, test_x_unseen = X_all[train_index], X_all[test_index]\n",
    "    train_y, test_y_unseen = y[train_index], y[test_index]\n",
    "    train_participant, test_participant_unseen = y_participant[train_index], y_participant[test_index]\n",
    "    train_time, test_time_unseen = X_time[train_index], X_time[test_index]\n",
    "    participant_ids = train_participant.copy()\n",
    "    train_participant = OneHotEncoder().fit_transform(train_participant.reshape(-1,1)).todense()\n",
    "    train_x, test_x, train_y, test_y,train_participant, test_participant,train_time,test_time,participant_ids_train, participant_ids_test = train_test_split(train_x,\n",
    "                                                            train_y,\n",
    "                                                            train_participant,\n",
    "                                                            train_time,\n",
    "                                                            participant_ids,\n",
    "                                                            test_size = 0.2,\n",
    "                                                            random_state=42,\n",
    "                                                            stratify=participant_ids)   \n",
    "    test_seen_pred = model.predict(test_x[:,:,index])\n",
    "    test_unseen_pred = model.predict(test_x_unseen[:,:,index])\n",
    "    print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_seen_pred,axis=1)))\n",
    "#     X_seen,y_seen = get_windows(test_seen_pred,test_time,participant_ids_test)\n",
    "#     X_unseen,y_unseen = get_windows(test_unseen_pred,test_time_unseen,test_participant_unseen)\n",
    "#     y_unseen = np.array([-1]*len(y_unseen))\n",
    "#     X_total = np.concatenate([X_seen,X_unseen])\n",
    "#     y_total = list(y_seen)+list(y_unseen)\n",
    "#     df = pd.DataFrame({'pred':list(X_total),'true':y_total})\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_mean'] = df['pred'].apply(lambda a:np.mean(a,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['argmax'] = df['column_mean'].apply(lambda a:np.argmax(a))\n",
    "df['max'] = df['column_mean'].apply(lambda a:np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04466666666666667"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(df['true'],df['argmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape,test_x.shape,val_x.shape,train_participant.shape,test_participant.shape,val_participant.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate, Flatten,LeakyReLU, Activation, RepeatVector, Permute, Multiply, Lambda, Dense, merge# Define a regular layer instead of writing a custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=(256,1),act='relu',loss=\"categorical_crossentropy\",opt='adam',n_classes=350):\n",
    "    model =  Sequential()\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(100,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(100,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(50,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(n_classes,activation='softmax',kernel_initializer='normal'))\n",
    "    model.compile(loss=loss,optimizer=opt,metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(participant_ids_train))\n",
    "model = get_model(input_shape=(256,3),n_classes=n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "filepath = '../model_files/base_cnn_8_seconds_acl_filtered_wesad.hdf5'\n",
    "# model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = model.fit(train_x,train_participant,validation_data=(val_x,val_participant), epochs=400, batch_size=200,\n",
    "          callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(filepath)\n",
    "test_participant_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#filtered_acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#filtered ppg+filtered_acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#filtered ppg+acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#filtered ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#ppg+acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#ppg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "print(accuracy_score(np.argmax(test_participant,axis=1),np.argmax(test_participant_pred,axis=1)))\n",
    "#acl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
