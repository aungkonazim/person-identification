{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory = '../data/WESAD.zip'\n",
    "output_directory = '../data/'\n",
    "\n",
    "os.listdir(output_directory)\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(directory, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Individual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy import signal\n",
    "from scipy.stats import skew,kurtosis,iqr\n",
    "import pickle\n",
    "from peak_valley import compute_peak_valley\n",
    "from respiration_feature import rip_cycle_feature_computation\n",
    "filelists = ['../data/WESAD/'+a+'/'+a+'.pkl' for a in os.listdir('../data/WESAD/') if a[-1] not in ['s','f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.signal import find_peaks\n",
    "plt.close('all')\n",
    "def filter_data(X,\n",
    "                Fs=64,\n",
    "                low_cutoff=.5,\n",
    "                high_cutoff=3.0,\n",
    "                filter_order=1):\n",
    "    \"\"\"\n",
    "    Bandpass Filter of single channel\n",
    "\n",
    "    :param X: input data\n",
    "    :param Fs: sampling freq.\n",
    "    :param low_cutoff: low passband\n",
    "    :param high_cutoff: high passband\n",
    "    :param filter_order: no of taps in FIR filter\n",
    "\n",
    "    :return: filtered version of input data\n",
    "    \"\"\"\n",
    "    X1 = X.reshape(-1,1)\n",
    "    X1 = signal.detrend(X1,axis=0,type='constant')\n",
    "    b = signal.firls(filter_order,np.array([0,low_cutoff-.1, low_cutoff, high_cutoff ,high_cutoff+.5,Fs/2]),np.array([0, 0 ,1 ,1 ,0, 0]),\n",
    "                     np.array([100*0.02,0.02,0.02]),fs=Fs)\n",
    "    X2 = signal.convolve(X1.reshape(-1),b,mode='same')\n",
    "    return X2\n",
    "\n",
    "class heart_rate:\n",
    "    def __init__(self,lower_hr_range=.7,higher_hr_range=3.5,height=.2):\n",
    "        self.hr_now = 0\n",
    "        self.history_hr = []\n",
    "        self.lower_hr_range = lower_hr_range\n",
    "        self.higher_hr_range = higher_hr_range\n",
    "        self.height = height\n",
    "        self.previous = 0\n",
    "        self.step = 2\n",
    "    \n",
    "    def filter_frequencies(self,x_x,f_x,pxx_x):\n",
    "        x_x = np.array(x_x)\n",
    "        x_x = x_x[f_x[x_x]>self.lower_hr_range]\n",
    "        x_x = x_x[f_x[x_x]<self.higher_hr_range]\n",
    "        f_x = f_x[x_x]\n",
    "        pxx_x = pxx_x[x_x]\n",
    "        return f_x,pxx_x\n",
    "    \n",
    "    def get_peaks(self,data,fs,nperseg,nfft):\n",
    "        f_x, pxx_x = signal.welch(data,fs=fs,nperseg=nperseg,nfft=nfft)\n",
    "        f_x = f_x.reshape(-1)\n",
    "        pxx_x = pxx_x/np.max(pxx_x)\n",
    "        x_x, _ = find_peaks(pxx_x, height=self.height)\n",
    "        f,pxx = self.filter_frequencies(x_x,f_x,pxx_x)\n",
    "        ppg = np.array(list(zip(f,pxx)))\n",
    "        if len(ppg)==0:\n",
    "            return []\n",
    "        ppg = ppg[ppg[:,1].argsort()]\n",
    "        return ppg\n",
    "    \n",
    "    def get_rr_value(self,values,acc_window,ecg_rr,Fs=64,nfft=12000):\n",
    "        \"\"\"\n",
    "        Get Mean RR interval\n",
    "\n",
    "        :param values: single channel ppg data\n",
    "        :param Fs: sampling frequency\n",
    "        :param nfft: FFT no. of points\n",
    "        :return: Mean RR interval Information\n",
    "        \"\"\"\n",
    "        values = filter_data(values)\n",
    "        ppg = self.get_peaks(values,Fs,values.shape[0],nfft)[-3:]\n",
    "        \n",
    "        if len(ppg)==0:\n",
    "            if len(self.history_hr)==0:\n",
    "                return 0\n",
    "            self.hr_now = np.mean(self.history_hr)\n",
    "            self.history_hr.append(self.hr_now)\n",
    "            self.history_hr  =self.history_hr[-6:]\n",
    "            return 60000/self.hr_now\n",
    "        \n",
    "        aclx = list(self.get_peaks(acc_window[:,0],Fs//2,acc_window.shape[0],nfft)[-1:])\n",
    "        acly = list(self.get_peaks(acc_window[:,1],Fs//2,acc_window.shape[0],nfft)[-1:])\n",
    "        aclz = list(self.get_peaks(acc_window[:,2],Fs//2,acc_window.shape[0],nfft)[-1:])\n",
    "        acl_unwanted = np.array(aclx+acly+aclz)\n",
    "        if len(acl_unwanted)>0:\n",
    "            acl_unwanted = acl_unwanted[:,0]*60\n",
    "            hr_now = 0\n",
    "            for k in range(1,len(ppg)+1):\n",
    "                hr_temp = ppg[-1*k,0]*60\n",
    "                if len(acl_unwanted[np.where((acl_unwanted>hr_temp-self.step)&(acl_unwanted<hr_temp+self.step))[0]])==0:\n",
    "                    hr_now = hr_temp\n",
    "                    break\n",
    "        else:\n",
    "            hr_now = ppg[-1,0]*60\n",
    "        \n",
    "        if hr_now==0:\n",
    "            hr_now = ppg[-1,0]*60\n",
    "        \n",
    "\n",
    "        if not self.hr_now:\n",
    "            self.hr_now = hr_now\n",
    "            self.history_hr.append(self.hr_now)\n",
    "            self.history_hr  =self.history_hr[-6:]\n",
    "            return 60000/self.hr_now\n",
    "        else:\n",
    "            if abs(self.hr_now-hr_now)>15:\n",
    "                if self.previous>5:\n",
    "                    self.history_hr.append(hr_now)\n",
    "                    self.hr_now = np.mean(self.history_hr)\n",
    "                    self.history_hr.append(self.hr_now)\n",
    "                    self.history_hr  =self.history_hr[-6:]\n",
    "                    self.previous=1\n",
    "                    return 60000/self.hr_now\n",
    "                else:\n",
    "                    self.hr_now = np.mean(self.history_hr)\n",
    "                    self.history_hr.append(self.hr_now)\n",
    "                    self.history_hr = self.history_hr[-6:]\n",
    "                    self.previous+=1\n",
    "                    return 60000/self.hr_now\n",
    "                    \n",
    "            else:\n",
    "                self.hr_now = hr_now\n",
    "                self.history_hr.append(self.hr_now)\n",
    "                self.history_hr  =self.history_hr[-6:]\n",
    "                return 60000/self.hr_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  15 | elapsed:  3.8min remaining:  3.3min\n",
      "[Parallel(n_jobs=20)]: Done  15 out of  15 | elapsed:  5.0min finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "%matplotlib notebook\n",
    "def get_ecg_rr(ecg_data):\n",
    "    detectors = Detectors(700)\n",
    "    rpeaks = detectors.hamilton_detector(ecg_data[:,1])\n",
    "    ecg_r_ts = ecg_data[np.array(rpeaks),0]\n",
    "    ecg_rr_ts = ecg_r_ts[1:]\n",
    "    ecg_rr_sample = np.diff(ecg_r_ts)\n",
    "    ecg_rr = pd.DataFrame(np.vstack([ecg_rr_ts,ecg_rr_sample]).T,columns=['time','rr'])\n",
    "    ecg_rr['timestamp'] = ecg_rr['time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    return ecg_rr\n",
    "\n",
    "def bandpass_filter_ppg(data,Fs=64,fil_type='ppg'):\n",
    "    X0 = data[:,1]\n",
    "    X1 = signal.detrend(X0,axis=0,type='constant')\n",
    "    X2 = np.zeros((np.shape(X1)[0],data.shape[1]))\n",
    "    nyq = Fs/2\n",
    "    b = signal.firls(219,np.array([0,0.3,0.5,3,3.5,nyq]),\n",
    "                              np.array([0,0,1,1,0,0]),np.array([10,1,1]),nyq=nyq)\n",
    "    a = [1]\n",
    "    X2[:,0] = data[:,0]\n",
    "    X2[:,1] = signal.filtfilt(b, a, X1)\n",
    "    return X2\n",
    "\n",
    "def bandpass_filter_respiration(data,Fs=700,fil_type='ppg'):\n",
    "    X0 = data[:,1]\n",
    "    X1 = signal.detrend(X0,axis=0,type='constant')\n",
    "    X2 = np.zeros((np.shape(X1)[0],data.shape[1]))\n",
    "    nyq = Fs/2\n",
    "    b = signal.firls(219,np.array([0,0.02,0.05,1,1.5,nyq]),\n",
    "                              np.array([0,0,1,1,0,0]),np.array([10,1,1]),nyq=nyq)\n",
    "    a = [1]\n",
    "    X2[:,0] = data[:,0]\n",
    "    X2[:,1] = signal.filtfilt(b, a, X1)\n",
    "    return X2\n",
    "\n",
    "def get_quality_features(ppg_data,ppg_fs=64,window_size=2.5):\n",
    "    ppg_data_final = []\n",
    "    n = int(ppg_fs*window_size/2)\n",
    "    for i in range(n,ppg_data.shape[0]-n,1):\n",
    "        tmp = []\n",
    "        tmp.append(ppg_data[i,0])\n",
    "        tmp.append(ppg_data[i,1])\n",
    "        tmp.extend([-1]*4)\n",
    "#         sample = ppg_data[(i-n):(i+n),1]\n",
    "#         tmp.append(skew(sample))\n",
    "#         tmp.append(kurtosis(sample))\n",
    "#         tmp.append(iqr(sample))\n",
    "#         f,pxx = signal.welch(sample,fs=ppg_fs,nperseg=len(sample)//2,nfft=10000,axis=0)\n",
    "#         tmp.append(np.trapz(pxx[np.where((f>=.8)&(f<=2.5))[0]])/np.trapz(pxx))\n",
    "        ppg_data_final.append(np.array(tmp))\n",
    "    return np.array(ppg_data_final)\n",
    "\n",
    "\n",
    "def save_participant_data(filename,ecg_fs = 700,ppg_fs = 64,acc_fs=32,window_size=8):\n",
    "    data = pickle.load(open(filename,'rb'),encoding='latin1')\n",
    "    ppg_data = data['signal']['wrist']['BVP']\n",
    "    acc_data = data['signal']['wrist']['ACC']/64\n",
    "    ecg_data = data['signal']['chest']['ECG']\n",
    "    respiration_data = data['signal']['chest']['Resp']\n",
    "    label_data = data['label']\n",
    "    total_seconds = ppg_data.shape[0]/ppg_fs\n",
    "    start_ts = datetime.utcnow().timestamp()\n",
    "    ecg_ts = start_ts + np.arange(0,total_seconds,1/ecg_fs)\n",
    "    acc_ts = start_ts + np.arange(0,total_seconds,1/acc_fs)\n",
    "    \n",
    "    label_data = np.concatenate([ecg_ts.reshape(-1,1),label_data.reshape(-1,1)],axis=1)\n",
    "    acc_data = np.concatenate([acc_ts.reshape(-1,1),acc_data],axis=1)\n",
    "    respiration_ts = ecg_ts\n",
    "    respiration_data = np.vstack([respiration_ts,respiration_data.reshape(-1)]).T\n",
    "    \n",
    "    ecg_data = np.vstack([ecg_ts,ecg_data.reshape(-1)]).T\n",
    "    ecg_rr1 = get_ecg_rr(ecg_data)\n",
    "    ecg_rr = ecg_rr1.values\n",
    "    \n",
    "    ppg_ts = start_ts + np.arange(0,total_seconds,1/ppg_fs)\n",
    "    \n",
    "    ppg_data = np.vstack([ppg_ts,ppg_data.reshape(-1)]).T\n",
    "    respiration_data = bandpass_filter_respiration(respiration_data,Fs=ecg_fs,fil_type='ppg')\n",
    "    respiration_data[:,0] = respiration_data[:,0]*1000\n",
    "    peak_index,valley_index = compute_peak_valley(respiration_data)\n",
    "    peak_data = respiration_data[peak_index]\n",
    "    valley_data = respiration_data[valley_index]\n",
    "    rip_feature = rip_cycle_feature_computation(peak_data,valley_data)[:,:5]\n",
    "    rip_feature[:,:2] = rip_feature[:,:2]/1000\n",
    "    ppg_data = get_quality_features(ppg_data)\n",
    "    ppg_data = pd.DataFrame(ppg_data,columns=['time','ppg','skew','kurtosis','iqr','relative_power']).dropna().sort_values('time').reset_index(drop=True)\n",
    "    ppg_data['timestamp'] = ppg_data['time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    respiration_data[:,0] = respiration_data[:,0]/1000\n",
    "    all_data = []\n",
    "    for i in range(0,ppg_data.shape[0]-window_size*ppg_fs,window_size*ppg_fs//4):\n",
    "        a = ppg_data.loc[i:i+window_size*ppg_fs-1]\n",
    "        b = respiration_data[np.where((respiration_data[:,0]>=a['time'].min())&(respiration_data[:,0]<a['time'].max()))[0],1].reshape(-1,1)\n",
    "        all_data.append([a['time'].min(),a['time'].max(),\n",
    "                         a[['time','ppg','skew','kurtosis','iqr','relative_power']].sort_values('time').reset_index(drop=True),b])\n",
    "    \n",
    "    ppg_windows = pd.DataFrame(all_data,columns=['start_time','end_time','data','respiration'])\n",
    "    ppg_windows['ecg_rr'] = ppg_windows.apply(lambda a:np.mean(ecg_rr[np.where((ecg_rr[:,0]>=a['start_time'])&(ecg_rr[:,0]<a['end_time']))[0],1]),axis=1)\n",
    "    ppg_windows['inspiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],2]),axis=1)\n",
    "    ppg_windows['expiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],3]),axis=1)\n",
    "    ppg_windows['respiration_duration'] = ppg_windows.apply(lambda a:np.mean(rip_feature[np.where((rip_feature[:,1]>=a['start_time'])&(rip_feature[:,0]<a['end_time']))[0],4]),axis=1)\n",
    "    ppg_windows['acc_window'] = ppg_windows.apply(lambda a: acc_data[np.where((acc_data[:,0]>=a['start_time'])&(acc_data[:,0]<a['end_time']))[0],:],axis=1)\n",
    "    ppg_windows['label'] = ppg_windows.apply(lambda a: mode(label_data[np.where((label_data[:,0]>=a['start_time'])&(label_data[:,0]<a['end_time']))[0],1])[0][0],axis=1)\n",
    "    \n",
    "    ppg_windows = ppg_windows.sort_values('start_time').reset_index(drop=True)\n",
    "    hr = heart_rate()\n",
    "    ppg_rr_col = []\n",
    "    for i,a in ppg_windows.iterrows():\n",
    "        ppg_rr_col.append(hr.get_rr_value(a['data'].sort_values('time').reset_index(drop=True)['ppg'].values,\n",
    "                                        a['acc_window'][a['acc_window'][:,0].argsort(),1:],\n",
    "                                        a['ecg_rr']*1000))\n",
    "        \n",
    "        \n",
    "    ppg_windows['ppg_rr'] = np.array(ppg_rr_col)/1000\n",
    "    if not os.path.isdir(output_directory+str(window_size)):\n",
    "        os.makedirs(output_directory+str(window_size))\n",
    "    final_path = output_directory+str(window_size)+'/'\n",
    "    participant_name = filename.split('/')[-1]\n",
    "    pickle.dump(ppg_windows,open(final_path+participant_name,'wb'))\n",
    "    return []\n",
    "\n",
    "from joblib import Parallel,delayed\n",
    "output_directory = '../data/'\n",
    "final = Parallel(n_jobs=20,verbose=2)(delayed(save_participant_data)(f,window_size=8) for f in filelists)\n",
    "# output = [save_participant_data(f,window_size=8) for f in filelists[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42928,) (42928,) (42928,) (42928, 30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "filepath = '../data/8/'\n",
    "filelists = [filepath+a for a in os.listdir(filepath) if a[-1] not in ['s','f']]\n",
    "from datetime import datetime\n",
    "y_stress = []\n",
    "y_participant = []\n",
    "X_hr = []\n",
    "X_time = []\n",
    "import pickle\n",
    "for i,f in enumerate(filelists):\n",
    "    data = pickle.load(open(f,'rb'))\n",
    "#     data['ppg_rr'] = (data['ppg_rr'] - data['ppg_rr'].mean())/data['ppg_rr'].std()\n",
    "    data = data.sort_values('start_time').reset_index(drop=True)\n",
    "    data['timestamp'] = data['start_time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "    for j in range(0,data.shape[0],1):\n",
    "        temp = data[j:(j+30)]\n",
    "        if temp.shape[0]!=30:\n",
    "            continue\n",
    "        labels = temp['label'].values\n",
    "        y_stress.append(mode(labels)[0][0])\n",
    "        X_hr.append(temp['ppg_rr'].values.reshape(1,30))\n",
    "        y_participant.append(i)\n",
    "        X_time.append(temp['start_time'].values[0])\n",
    "\n",
    "y_stress = np.array(y_stress)\n",
    "y_participant = np.array(y_participant)\n",
    "X_time = np.array(X_time)\n",
    "X_hr = np.concatenate(X_hr)\n",
    "print(X_time.shape,y_stress.shape,y_participant.shape,X_hr.shape)\n",
    "\n",
    "import pickle\n",
    "pickle.dump([X_hr,y_stress,y_participant,X_time],open('../data/tabular_data_60_seconds_ppg_rr.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filepath = '../data/8/'\n",
    "filelists = [filepath+a for a in os.listdir(filepath) if a[-1] not in ['s','f']]\n",
    "\n",
    "from datetime import datetime\n",
    "X_ppg = []\n",
    "X_acl = []\n",
    "y = []\n",
    "y_participant = []\n",
    "X_hr_windows = []\n",
    "X_time = []\n",
    "import pickle\n",
    "for i,f in enumerate(filelists):\n",
    "    data = pickle.load(open(f,'rb'))\n",
    "    data = data.sort_values('start_time').reset_index(drop=True)\n",
    "    X_time.extend(list(data['start_time'].values))\n",
    "    X_ppg.extend([a.values[:,1:3].reshape(1,-1,2) for a in data['data'].values])\n",
    "    X_acl.extend([a[:,1:].reshape(1,-1,6) for a in data['acc_window'].values])\n",
    "    y.extend(list(data['ecg_rr'].values))\n",
    "    y_participant.extend([i]*data.shape[0])\n",
    "    data['participant'] = i\n",
    "    data['timestamp'] = data['start_time'].apply(lambda a:datetime.utcfromtimestamp(a))\n",
    "#     data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "#     hr_windows = [df[['ecg_rr','participant']].values for i,df in \n",
    "#                   data.groupby(pd.Grouper(key='timestamp',freq='20S')) if df.shape[0]==10]\n",
    "#     X_hr_windows.extend(hr_windows)\n",
    "\n",
    "X_acl = np.concatenate(X_acl)\n",
    "X_ppg = np.concatenate(X_ppg)\n",
    "y = np.array(y)\n",
    "y_participant = np.array(y_participant)\n",
    "X_time = np.array(X_time)\n",
    "print(X_time.shape,X_acl.shape,X_ppg.shape,y.shape,y_participant.shape)\n",
    "\n",
    "import pickle\n",
    "pickle.dump([X_acl,X_ppg,y,y_participant,X_time],open('../data/tabular_data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
