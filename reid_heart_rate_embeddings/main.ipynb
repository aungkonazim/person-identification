{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_hr,y_stress,y_participant,X_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr.p','rb'))\n",
    "\n",
    "X_hr = X_hr.reshape(-1,30,1)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,LeaveOneGroupOut,LeavePGroupsOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from keras.layers import Conv1D,Reshape,BatchNormalization,TimeDistributed, \\\n",
    "Dropout,Input,MaxPooling1D,Flatten,Dense,Input, GaussianNoise,LSTM, Bidirectional, Input\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer,LabelEncoder\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "train_participant = y_participant.copy()\n",
    "\n",
    "np.unique(y_participant),train_participant.shape\n",
    "\n",
    "train_x = X_hr\n",
    "train_y = y_participant\n",
    "\n",
    "train_x, test_x, train_y, test_y,participant_ids_train, participant_ids_test = train_test_split(X_hr,\n",
    "                                                            train_participant,\n",
    "                                                            y_participant,\n",
    "                                                            test_size = 0.2,\n",
    "                                                            random_state=41,\n",
    "                                                            stratify=y_participant)\n",
    "train_x, val_x, train_y, val_y, participant_ids_train, participant_ids_val  = train_test_split(train_x,\n",
    "                                                            train_y,\n",
    "                                                            participant_ids_train,\n",
    "                                                            test_size = 0.1,\n",
    "                                                            random_state=41,\n",
    "                                                            stratify=participant_ids_train)\n",
    "train_x.shape,test_x.shape,val_x.shape,train_y.shape,test_y.shape,val_y.shape,participant_ids_train.shape\n",
    "\n",
    "def get_model(input_shape=(30,1),act='relu',loss=\"categorical_crossentropy\",opt='adam',n_classes=350):\n",
    "    model =  Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Reshape(input_shape))\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='linear',kernel_initializer='normal',padding='same'))\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(200,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(300,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(50,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes//2,activation=None))\n",
    "    model.add(Dense(n_classes,activation=None))\n",
    "#     model.add(Dense(n_classes,activation='softmax',kernel_initializer='normal'))\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))\n",
    "#     model.compile(loss=loss,optimizer=opt,metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n",
    "n_classes = 1000\n",
    "model = get_model(input_shape=(30,1),n_classes=n_classes)\n",
    "\n",
    "model.compile(optimizer='adam',loss=tfa.losses.TripletSemiHardLoss())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.layers[0]\n",
    "\n",
    "from keras.models import load_model\n",
    "filepath = '../model_files/base_cnn_60_seconds_ppg_hr_wesad.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = model.fit(train_x,train_y,validation_data=(val_x,val_y), epochs=400, batch_size=200,\n",
    "          callbacks=callbacks_list,shuffle=True)\n",
    "\n",
    "model = load_model(filepath)\n",
    "train_embeddings = model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_rank_accuracy(train_embeddings,train_y,rank = 10):\n",
    "    distance_matrix = euclidean_distances(train_embeddings)\n",
    "    distance_matrix_2d = np.zeros((distance_matrix.shape[0],\n",
    "                               distance_matrix.shape[0],\n",
    "                               2))\n",
    "    distance_matrix_2d[:,:,0] = distance_matrix\n",
    "    train_y_matrix = np.concatenate([train_y.reshape(1,-1)]*distance_matrix.shape[0])\n",
    "    distance_matrix_2d[:,:,1] = train_y_matrix\n",
    "    match = 0\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        row = distance_matrix_2d[i]\n",
    "        row = row[row[:,0].argsort(),:]\n",
    "        if rank==1:\n",
    "            if train_y[i]==row[1,1]:\n",
    "                match+=1\n",
    "        else:\n",
    "            row = set(row[1:(rank+1)][:,1])\n",
    "            if train_y[i] in row:\n",
    "                match+=1\n",
    "    return match/distance_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999579383311224 0.9998705794803766 0.9999029346102825\n"
     ]
    }
   ],
   "source": [
    "rank_1 = give_rank_accuracy(train_embeddings,train_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(train_embeddings,train_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(train_embeddings,train_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664570230607966 0.9811320754716981 0.9842767295597484\n"
     ]
    }
   ],
   "source": [
    "rank_1 = give_rank_accuracy(test_embeddings,test_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(test_embeddings,test_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(test_embeddings,test_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,y_stress,test_y,X_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr_dalia.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(-1,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9881862404447533 0.990271021542738 0.9916608756080612\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = model.predict(test_x)\n",
    "rank_1 = give_rank_accuracy(test_embeddings,test_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(test_embeddings,test_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(test_embeddings,test_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f1f331f6d801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y,train_y_pred))\n",
    "print(confusion_matrix(train_y,train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
