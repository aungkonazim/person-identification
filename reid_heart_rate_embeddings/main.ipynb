{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] (64247,)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 30, 1)]           0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 7)                 934707    \n",
      "_________________________________________________________________\n",
      "feature1 (Dense)             (None, 15)                120       \n",
      "_________________________________________________________________\n",
      "feature (Lambda)             (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 15)                240       \n",
      "=================================================================\n",
      "Total params: 935,067\n",
      "Trainable params: 933,767\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "93/93 [==============================] - ETA: 0s - loss: 3.6678 - output_loss: 2.6699 - feature_loss: 0.9979\n",
      "Epoch 00001: val_output_loss improved from inf to 2.65088, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 6s 63ms/step - loss: 3.6678 - output_loss: 2.6699 - feature_loss: 0.9979 - val_loss: 3.6485 - val_output_loss: 2.6509 - val_feature_loss: 0.9976\n",
      "Epoch 2/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.5573 - output_loss: 2.5601 - feature_loss: 0.9972\n",
      "Epoch 00002: val_output_loss improved from 2.65088 to 2.61560, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.5571 - output_loss: 2.5600 - feature_loss: 0.9972 - val_loss: 3.6123 - val_output_loss: 2.6156 - val_feature_loss: 0.9967\n",
      "Epoch 3/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.4482 - output_loss: 2.4516 - feature_loss: 0.9966\n",
      "Epoch 00003: val_output_loss improved from 2.61560 to 2.60851, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.4478 - output_loss: 2.4513 - feature_loss: 0.9965 - val_loss: 3.6049 - val_output_loss: 2.6085 - val_feature_loss: 0.9964\n",
      "Epoch 4/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.3639 - output_loss: 2.3677 - feature_loss: 0.9962\n",
      "Epoch 00004: val_output_loss improved from 2.60851 to 2.43308, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.3637 - output_loss: 2.3676 - feature_loss: 0.9962 - val_loss: 3.4291 - val_output_loss: 2.4331 - val_feature_loss: 0.9960\n",
      "Epoch 5/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.2963 - output_loss: 2.3004 - feature_loss: 0.9959\n",
      "Epoch 00005: val_output_loss improved from 2.43308 to 2.28948, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.2964 - output_loss: 2.3004 - feature_loss: 0.9959 - val_loss: 3.2849 - val_output_loss: 2.2895 - val_feature_loss: 0.9954\n",
      "Epoch 6/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.2351 - output_loss: 2.2394 - feature_loss: 0.9957\n",
      "Epoch 00006: val_output_loss improved from 2.28948 to 2.23805, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.2352 - output_loss: 2.2396 - feature_loss: 0.9956 - val_loss: 3.2332 - val_output_loss: 2.2381 - val_feature_loss: 0.9951\n",
      "Epoch 7/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.1736 - output_loss: 2.1783 - feature_loss: 0.9954\n",
      "Epoch 00007: val_output_loss improved from 2.23805 to 2.17387, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.1736 - output_loss: 2.1782 - feature_loss: 0.9953 - val_loss: 3.1687 - val_output_loss: 2.1739 - val_feature_loss: 0.9949\n",
      "Epoch 8/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.1179 - output_loss: 2.1228 - feature_loss: 0.9950\n",
      "Epoch 00008: val_output_loss improved from 2.17387 to 2.13774, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.1176 - output_loss: 2.1226 - feature_loss: 0.9950 - val_loss: 3.1323 - val_output_loss: 2.1377 - val_feature_loss: 0.9945\n",
      "Epoch 9/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.0627 - output_loss: 2.0681 - feature_loss: 0.9947\n",
      "Epoch 00009: val_output_loss improved from 2.13774 to 2.09395, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.0625 - output_loss: 2.0678 - feature_loss: 0.9947 - val_loss: 3.0880 - val_output_loss: 2.0939 - val_feature_loss: 0.9940\n",
      "Epoch 10/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 3.0005 - output_loss: 2.0063 - feature_loss: 0.9942\n",
      "Epoch 00010: val_output_loss improved from 2.09395 to 2.03941, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.0003 - output_loss: 2.0061 - feature_loss: 0.9942 - val_loss: 3.0328 - val_output_loss: 2.0394 - val_feature_loss: 0.9934\n",
      "Epoch 11/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.9378 - output_loss: 1.9442 - feature_loss: 0.9937\n",
      "Epoch 00011: val_output_loss improved from 2.03941 to 1.92251, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.9376 - output_loss: 1.9440 - feature_loss: 0.9936 - val_loss: 2.9151 - val_output_loss: 1.9225 - val_feature_loss: 0.9926\n",
      "Epoch 12/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.8785 - output_loss: 1.8855 - feature_loss: 0.9930\n",
      "Epoch 00012: val_output_loss improved from 1.92251 to 1.91855, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.8784 - output_loss: 1.8854 - feature_loss: 0.9930 - val_loss: 2.9108 - val_output_loss: 1.9185 - val_feature_loss: 0.9922\n",
      "Epoch 13/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.8164 - output_loss: 1.8240 - feature_loss: 0.9924\n",
      "Epoch 00013: val_output_loss improved from 1.91855 to 1.77943, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.8163 - output_loss: 1.8239 - feature_loss: 0.9924 - val_loss: 2.7699 - val_output_loss: 1.7794 - val_feature_loss: 0.9905\n",
      "Epoch 14/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.7490 - output_loss: 1.7573 - feature_loss: 0.9917\n",
      "Epoch 00014: val_output_loss improved from 1.77943 to 1.73807, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.7488 - output_loss: 1.7571 - feature_loss: 0.9916 - val_loss: 2.7290 - val_output_loss: 1.7381 - val_feature_loss: 0.9909\n",
      "Epoch 15/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.6893 - output_loss: 1.6984 - feature_loss: 0.9908\n",
      "Epoch 00015: val_output_loss improved from 1.73807 to 1.65367, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.6890 - output_loss: 1.6982 - feature_loss: 0.9908 - val_loss: 2.6427 - val_output_loss: 1.6537 - val_feature_loss: 0.9890\n",
      "Epoch 16/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.6346 - output_loss: 1.6446 - feature_loss: 0.9900\n",
      "Epoch 00016: val_output_loss improved from 1.65367 to 1.61057, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.6345 - output_loss: 1.6446 - feature_loss: 0.9899 - val_loss: 2.5995 - val_output_loss: 1.6106 - val_feature_loss: 0.9889\n",
      "Epoch 17/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.5757 - output_loss: 1.5866 - feature_loss: 0.9891\n",
      "Epoch 00017: val_output_loss did not improve from 1.61057\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.5753 - output_loss: 1.5863 - feature_loss: 0.9890 - val_loss: 2.6105 - val_output_loss: 1.6227 - val_feature_loss: 0.9878\n",
      "Epoch 18/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.5178 - output_loss: 1.5299 - feature_loss: 0.9880\n",
      "Epoch 00018: val_output_loss improved from 1.61057 to 1.47831, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.5177 - output_loss: 1.5297 - feature_loss: 0.9879 - val_loss: 2.4640 - val_output_loss: 1.4783 - val_feature_loss: 0.9857\n",
      "Epoch 19/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.4613 - output_loss: 1.4746 - feature_loss: 0.9867\n",
      "Epoch 00019: val_output_loss improved from 1.47831 to 1.44259, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.4611 - output_loss: 1.4745 - feature_loss: 0.9867 - val_loss: 2.4260 - val_output_loss: 1.4426 - val_feature_loss: 0.9834\n",
      "Epoch 20/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.4068 - output_loss: 1.4211 - feature_loss: 0.9857\n",
      "Epoch 00020: val_output_loss improved from 1.44259 to 1.38762, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.4074 - output_loss: 1.4217 - feature_loss: 0.9857 - val_loss: 2.3709 - val_output_loss: 1.3876 - val_feature_loss: 0.9833\n",
      "Epoch 21/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.3588 - output_loss: 1.3741 - feature_loss: 0.9847\n",
      "Epoch 00021: val_output_loss improved from 1.38762 to 1.35016, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.3587 - output_loss: 1.3740 - feature_loss: 0.9846 - val_loss: 2.3317 - val_output_loss: 1.3502 - val_feature_loss: 0.9816\n",
      "Epoch 22/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.3134 - output_loss: 1.3305 - feature_loss: 0.9829\n",
      "Epoch 00022: val_output_loss improved from 1.35016 to 1.30026, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.3134 - output_loss: 1.3305 - feature_loss: 0.9829 - val_loss: 2.2809 - val_output_loss: 1.3003 - val_feature_loss: 0.9807\n",
      "Epoch 23/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.2647 - output_loss: 1.2829 - feature_loss: 0.9819\n",
      "Epoch 00023: val_output_loss improved from 1.30026 to 1.27628, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.2648 - output_loss: 1.2830 - feature_loss: 0.9818 - val_loss: 2.2561 - val_output_loss: 1.2763 - val_feature_loss: 0.9798\n",
      "Epoch 24/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.2202 - output_loss: 1.2399 - feature_loss: 0.9803\n",
      "Epoch 00024: val_output_loss improved from 1.27628 to 1.24977, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 2.2202 - output_loss: 1.2400 - feature_loss: 0.9802 - val_loss: 2.2277 - val_output_loss: 1.2498 - val_feature_loss: 0.9779\n",
      "Epoch 25/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.1811 - output_loss: 1.2023 - feature_loss: 0.9788\n",
      "Epoch 00025: val_output_loss improved from 1.24977 to 1.20636, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 2.1807 - output_loss: 1.2020 - feature_loss: 0.9786 - val_loss: 2.1816 - val_output_loss: 1.2064 - val_feature_loss: 0.9753\n",
      "Epoch 26/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.1437 - output_loss: 1.1668 - feature_loss: 0.9769\n",
      "Epoch 00026: val_output_loss improved from 1.20636 to 1.15286, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 2.1434 - output_loss: 1.1666 - feature_loss: 0.9768 - val_loss: 2.1255 - val_output_loss: 1.1529 - val_feature_loss: 0.9726\n",
      "Epoch 27/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.1059 - output_loss: 1.1302 - feature_loss: 0.9756\n",
      "Epoch 00027: val_output_loss improved from 1.15286 to 1.11426, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.1060 - output_loss: 1.1305 - feature_loss: 0.9755 - val_loss: 2.0890 - val_output_loss: 1.1143 - val_feature_loss: 0.9748\n",
      "Epoch 28/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.0652 - output_loss: 1.0924 - feature_loss: 0.9729\n",
      "Epoch 00028: val_output_loss improved from 1.11426 to 1.04467, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.0652 - output_loss: 1.0925 - feature_loss: 0.9728 - val_loss: 2.0109 - val_output_loss: 1.0447 - val_feature_loss: 0.9663\n",
      "Epoch 29/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 2.0262 - output_loss: 1.0560 - feature_loss: 0.9702\n",
      "Epoch 00029: val_output_loss improved from 1.04467 to 1.03268, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 2.0261 - output_loss: 1.0560 - feature_loss: 0.9701 - val_loss: 2.0022 - val_output_loss: 1.0327 - val_feature_loss: 0.9696\n",
      "Epoch 30/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.9920 - output_loss: 1.0233 - feature_loss: 0.9687\n",
      "Epoch 00030: val_output_loss improved from 1.03268 to 0.99426, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.9918 - output_loss: 1.0232 - feature_loss: 0.9686 - val_loss: 1.9601 - val_output_loss: 0.9943 - val_feature_loss: 0.9658\n",
      "Epoch 31/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.9576 - output_loss: 0.9906 - feature_loss: 0.9670\n",
      "Epoch 00031: val_output_loss improved from 0.99426 to 0.97268, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.9583 - output_loss: 0.9914 - feature_loss: 0.9669 - val_loss: 1.9351 - val_output_loss: 0.9727 - val_feature_loss: 0.9624\n",
      "Epoch 32/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.9255 - output_loss: 0.9614 - feature_loss: 0.9641\n",
      "Epoch 00032: val_output_loss improved from 0.97268 to 0.94296, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.9255 - output_loss: 0.9615 - feature_loss: 0.9640 - val_loss: 1.9033 - val_output_loss: 0.9430 - val_feature_loss: 0.9603\n",
      "Epoch 33/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.8881 - output_loss: 0.9267 - feature_loss: 0.9613\n",
      "Epoch 00033: val_output_loss improved from 0.94296 to 0.90266, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.8882 - output_loss: 0.9270 - feature_loss: 0.9612 - val_loss: 1.8595 - val_output_loss: 0.9027 - val_feature_loss: 0.9568\n",
      "Epoch 34/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.8681 - output_loss: 0.9089 - feature_loss: 0.9592\n",
      "Epoch 00034: val_output_loss did not improve from 0.90266\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.8685 - output_loss: 0.9093 - feature_loss: 0.9592 - val_loss: 1.8787 - val_output_loss: 0.9265 - val_feature_loss: 0.9523\n",
      "Epoch 35/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.8385 - output_loss: 0.8818 - feature_loss: 0.9567\n",
      "Epoch 00035: val_output_loss improved from 0.90266 to 0.88345, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.8380 - output_loss: 0.8816 - feature_loss: 0.9564 - val_loss: 1.8357 - val_output_loss: 0.8834 - val_feature_loss: 0.9522\n",
      "Epoch 36/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.8111 - output_loss: 0.8593 - feature_loss: 0.9518\n",
      "Epoch 00036: val_output_loss improved from 0.88345 to 0.83710, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.8114 - output_loss: 0.8597 - feature_loss: 0.9517 - val_loss: 1.7770 - val_output_loss: 0.8371 - val_feature_loss: 0.9399\n",
      "Epoch 37/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.7767 - output_loss: 0.8280 - feature_loss: 0.9488\n",
      "Epoch 00037: val_output_loss improved from 0.83710 to 0.82275, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.7762 - output_loss: 0.8277 - feature_loss: 0.9486 - val_loss: 1.7646 - val_output_loss: 0.8228 - val_feature_loss: 0.9419\n",
      "Epoch 38/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.7536 - output_loss: 0.8082 - feature_loss: 0.9454\n",
      "Epoch 00038: val_output_loss improved from 0.82275 to 0.80348, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.7533 - output_loss: 0.8082 - feature_loss: 0.9451 - val_loss: 1.7468 - val_output_loss: 0.8035 - val_feature_loss: 0.9433\n",
      "Epoch 39/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.7293 - output_loss: 0.7864 - feature_loss: 0.9429\n",
      "Epoch 00039: val_output_loss improved from 0.80348 to 0.77965, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.7295 - output_loss: 0.7868 - feature_loss: 0.9428 - val_loss: 1.7153 - val_output_loss: 0.7796 - val_feature_loss: 0.9356\n",
      "Epoch 40/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.7104 - output_loss: 0.7716 - feature_loss: 0.9388\n",
      "Epoch 00040: val_output_loss improved from 0.77965 to 0.77364, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.7108 - output_loss: 0.7721 - feature_loss: 0.9387 - val_loss: 1.7045 - val_output_loss: 0.7736 - val_feature_loss: 0.9308\n",
      "Epoch 41/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.6841 - output_loss: 0.7491 - feature_loss: 0.9350\n",
      "Epoch 00041: val_output_loss improved from 0.77364 to 0.72622, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.6839 - output_loss: 0.7491 - feature_loss: 0.9348 - val_loss: 1.6432 - val_output_loss: 0.7262 - val_feature_loss: 0.9170\n",
      "Epoch 42/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.6561 - output_loss: 0.7238 - feature_loss: 0.9322\n",
      "Epoch 00042: val_output_loss improved from 0.72622 to 0.72395, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.6563 - output_loss: 0.7241 - feature_loss: 0.9322 - val_loss: 1.6472 - val_output_loss: 0.7239 - val_feature_loss: 0.9232\n",
      "Epoch 43/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.6371 - output_loss: 0.7095 - feature_loss: 0.9276\n",
      "Epoch 00043: val_output_loss improved from 0.72395 to 0.70992, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.6369 - output_loss: 0.7096 - feature_loss: 0.9274 - val_loss: 1.6283 - val_output_loss: 0.7099 - val_feature_loss: 0.9184\n",
      "Epoch 44/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.6184 - output_loss: 0.6927 - feature_loss: 0.9257\n",
      "Epoch 00044: val_output_loss did not improve from 0.70992\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.6185 - output_loss: 0.6931 - feature_loss: 0.9255 - val_loss: 1.6356 - val_output_loss: 0.7186 - val_feature_loss: 0.9170\n",
      "Epoch 45/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5929 - output_loss: 0.6716 - feature_loss: 0.9212\n",
      "Epoch 00045: val_output_loss improved from 0.70992 to 0.66133, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.5931 - output_loss: 0.6719 - feature_loss: 0.9212 - val_loss: 1.5703 - val_output_loss: 0.6613 - val_feature_loss: 0.9089\n",
      "Epoch 46/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5798 - output_loss: 0.6613 - feature_loss: 0.9185\n",
      "Epoch 00046: val_output_loss improved from 0.66133 to 0.65246, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.5794 - output_loss: 0.6614 - feature_loss: 0.9180 - val_loss: 1.5578 - val_output_loss: 0.6525 - val_feature_loss: 0.9053\n",
      "Epoch 47/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5592 - output_loss: 0.6449 - feature_loss: 0.9144\n",
      "Epoch 00047: val_output_loss improved from 0.65246 to 0.63122, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.5585 - output_loss: 0.6448 - feature_loss: 0.9137 - val_loss: 1.5333 - val_output_loss: 0.6312 - val_feature_loss: 0.9021\n",
      "Epoch 48/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5403 - output_loss: 0.6290 - feature_loss: 0.9114\n",
      "Epoch 00048: val_output_loss improved from 0.63122 to 0.59144, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.5399 - output_loss: 0.6289 - feature_loss: 0.9110 - val_loss: 1.4823 - val_output_loss: 0.5914 - val_feature_loss: 0.8908\n",
      "Epoch 49/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5157 - output_loss: 0.6094 - feature_loss: 0.9064\n",
      "Epoch 00049: val_output_loss did not improve from 0.59144\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.5151 - output_loss: 0.6091 - feature_loss: 0.9060 - val_loss: 1.4804 - val_output_loss: 0.5915 - val_feature_loss: 0.8889\n",
      "Epoch 50/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.5000 - output_loss: 0.5956 - feature_loss: 0.9044\n",
      "Epoch 00050: val_output_loss improved from 0.59144 to 0.57683, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.4996 - output_loss: 0.5954 - feature_loss: 0.9042 - val_loss: 1.4551 - val_output_loss: 0.5768 - val_feature_loss: 0.8782\n",
      "Epoch 51/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4838 - output_loss: 0.5856 - feature_loss: 0.8981\n",
      "Epoch 00051: val_output_loss did not improve from 0.57683\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.4835 - output_loss: 0.5856 - feature_loss: 0.8979 - val_loss: 1.4888 - val_output_loss: 0.6008 - val_feature_loss: 0.8880\n",
      "Epoch 52/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4734 - output_loss: 0.5737 - feature_loss: 0.8997\n",
      "Epoch 00052: val_output_loss improved from 0.57683 to 0.55494, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.4727 - output_loss: 0.5733 - feature_loss: 0.8994 - val_loss: 1.4237 - val_output_loss: 0.5549 - val_feature_loss: 0.8687\n",
      "Epoch 53/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4578 - output_loss: 0.5628 - feature_loss: 0.8950\n",
      "Epoch 00053: val_output_loss improved from 0.55494 to 0.55364, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.4570 - output_loss: 0.5624 - feature_loss: 0.8946 - val_loss: 1.4143 - val_output_loss: 0.5536 - val_feature_loss: 0.8606\n",
      "Epoch 54/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4481 - output_loss: 0.5564 - feature_loss: 0.8917\n",
      "Epoch 00054: val_output_loss improved from 0.55364 to 0.55331, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.4489 - output_loss: 0.5572 - feature_loss: 0.8917 - val_loss: 1.4430 - val_output_loss: 0.5533 - val_feature_loss: 0.8897\n",
      "Epoch 55/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4190 - output_loss: 0.5361 - feature_loss: 0.8830\n",
      "Epoch 00055: val_output_loss improved from 0.55331 to 0.52716, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.4193 - output_loss: 0.5364 - feature_loss: 0.8829 - val_loss: 1.4013 - val_output_loss: 0.5272 - val_feature_loss: 0.8741\n",
      "Epoch 56/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.4012 - output_loss: 0.5204 - feature_loss: 0.8808\n",
      "Epoch 00056: val_output_loss did not improve from 0.52716\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.4013 - output_loss: 0.5205 - feature_loss: 0.8808 - val_loss: 1.4305 - val_output_loss: 0.5503 - val_feature_loss: 0.8802\n",
      "Epoch 57/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3943 - output_loss: 0.5155 - feature_loss: 0.8787\n",
      "Epoch 00057: val_output_loss improved from 0.52716 to 0.51548, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.3941 - output_loss: 0.5156 - feature_loss: 0.8785 - val_loss: 1.3789 - val_output_loss: 0.5155 - val_feature_loss: 0.8634\n",
      "Epoch 58/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3909 - output_loss: 0.5118 - feature_loss: 0.8790\n",
      "Epoch 00058: val_output_loss improved from 0.51548 to 0.46967, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.3904 - output_loss: 0.5116 - feature_loss: 0.8788 - val_loss: 1.3185 - val_output_loss: 0.4697 - val_feature_loss: 0.8488\n",
      "Epoch 59/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3728 - output_loss: 0.4977 - feature_loss: 0.8750\n",
      "Epoch 00059: val_output_loss did not improve from 0.46967\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.3718 - output_loss: 0.4971 - feature_loss: 0.8746 - val_loss: 1.3166 - val_output_loss: 0.4743 - val_feature_loss: 0.8422\n",
      "Epoch 60/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3479 - output_loss: 0.4791 - feature_loss: 0.8688\n",
      "Epoch 00060: val_output_loss improved from 0.46967 to 0.46613, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.3482 - output_loss: 0.4795 - feature_loss: 0.8687 - val_loss: 1.3126 - val_output_loss: 0.4661 - val_feature_loss: 0.8465\n",
      "Epoch 61/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3457 - output_loss: 0.4785 - feature_loss: 0.8672\n",
      "Epoch 00061: val_output_loss improved from 0.46613 to 0.45671, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.3451 - output_loss: 0.4781 - feature_loss: 0.8670 - val_loss: 1.2953 - val_output_loss: 0.4567 - val_feature_loss: 0.8386\n",
      "Epoch 62/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3088 - output_loss: 0.4537 - feature_loss: 0.8551\n",
      "Epoch 00062: val_output_loss improved from 0.45671 to 0.45514, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.3100 - output_loss: 0.4549 - feature_loss: 0.8551 - val_loss: 1.3003 - val_output_loss: 0.4551 - val_feature_loss: 0.8452\n",
      "Epoch 63/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3185 - output_loss: 0.4620 - feature_loss: 0.8565\n",
      "Epoch 00063: val_output_loss did not improve from 0.45514\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.3183 - output_loss: 0.4619 - feature_loss: 0.8563 - val_loss: 1.3051 - val_output_loss: 0.4625 - val_feature_loss: 0.8426\n",
      "Epoch 64/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.3008 - output_loss: 0.4477 - feature_loss: 0.8531\n",
      "Epoch 00064: val_output_loss did not improve from 0.45514\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.3007 - output_loss: 0.4478 - feature_loss: 0.8530 - val_loss: 1.2849 - val_output_loss: 0.4610 - val_feature_loss: 0.8239\n",
      "Epoch 65/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2826 - output_loss: 0.4358 - feature_loss: 0.8468\n",
      "Epoch 00065: val_output_loss improved from 0.45514 to 0.40632, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.2823 - output_loss: 0.4358 - feature_loss: 0.8465 - val_loss: 1.2243 - val_output_loss: 0.4063 - val_feature_loss: 0.8180\n",
      "Epoch 66/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2840 - output_loss: 0.4381 - feature_loss: 0.8459\n",
      "Epoch 00066: val_output_loss did not improve from 0.40632\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.2836 - output_loss: 0.4381 - feature_loss: 0.8455 - val_loss: 1.2346 - val_output_loss: 0.4089 - val_feature_loss: 0.8257\n",
      "Epoch 67/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2685 - output_loss: 0.4250 - feature_loss: 0.8435\n",
      "Epoch 00067: val_output_loss did not improve from 0.40632\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.2690 - output_loss: 0.4255 - feature_loss: 0.8434 - val_loss: 1.2524 - val_output_loss: 0.4283 - val_feature_loss: 0.8241\n",
      "Epoch 68/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2518 - output_loss: 0.4154 - feature_loss: 0.8363\n",
      "Epoch 00068: val_output_loss improved from 0.40632 to 0.40075, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.2520 - output_loss: 0.4159 - feature_loss: 0.8361 - val_loss: 1.2110 - val_output_loss: 0.4007 - val_feature_loss: 0.8102\n",
      "Epoch 69/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2485 - output_loss: 0.4125 - feature_loss: 0.8360\n",
      "Epoch 00069: val_output_loss did not improve from 0.40075\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.2478 - output_loss: 0.4122 - feature_loss: 0.8355 - val_loss: 1.2622 - val_output_loss: 0.4355 - val_feature_loss: 0.8267\n",
      "Epoch 70/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2258 - output_loss: 0.4007 - feature_loss: 0.8251\n",
      "Epoch 00070: val_output_loss did not improve from 0.40075\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.2256 - output_loss: 0.4007 - feature_loss: 0.8249 - val_loss: 1.2321 - val_output_loss: 0.4178 - val_feature_loss: 0.8143\n",
      "Epoch 71/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2210 - output_loss: 0.3951 - feature_loss: 0.8259\n",
      "Epoch 00071: val_output_loss improved from 0.40075 to 0.36519, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.2208 - output_loss: 0.3953 - feature_loss: 0.8255 - val_loss: 1.1410 - val_output_loss: 0.3652 - val_feature_loss: 0.7758\n",
      "Epoch 72/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.2150 - output_loss: 0.3916 - feature_loss: 0.8234\n",
      "Epoch 00072: val_output_loss did not improve from 0.36519\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.2152 - output_loss: 0.3920 - feature_loss: 0.8232 - val_loss: 1.1520 - val_output_loss: 0.3702 - val_feature_loss: 0.7818\n",
      "Epoch 73/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1961 - output_loss: 0.3851 - feature_loss: 0.8110\n",
      "Epoch 00073: val_output_loss did not improve from 0.36519\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1953 - output_loss: 0.3848 - feature_loss: 0.8105 - val_loss: 1.1723 - val_output_loss: 0.3853 - val_feature_loss: 0.7870\n",
      "Epoch 74/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1934 - output_loss: 0.3801 - feature_loss: 0.8133\n",
      "Epoch 00074: val_output_loss improved from 0.36519 to 0.35092, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1937 - output_loss: 0.3805 - feature_loss: 0.8132 - val_loss: 1.1079 - val_output_loss: 0.3509 - val_feature_loss: 0.7570\n",
      "Epoch 75/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1836 - output_loss: 0.3756 - feature_loss: 0.8080\n",
      "Epoch 00075: val_output_loss did not improve from 0.35092\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1833 - output_loss: 0.3756 - feature_loss: 0.8077 - val_loss: 1.1476 - val_output_loss: 0.3710 - val_feature_loss: 0.7766\n",
      "Epoch 76/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1724 - output_loss: 0.3700 - feature_loss: 0.8023\n",
      "Epoch 00076: val_output_loss did not improve from 0.35092\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1725 - output_loss: 0.3701 - feature_loss: 0.8023 - val_loss: 1.1299 - val_output_loss: 0.3645 - val_feature_loss: 0.7654\n",
      "Epoch 77/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1700 - output_loss: 0.3654 - feature_loss: 0.8046\n",
      "Epoch 00077: val_output_loss did not improve from 0.35092\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1705 - output_loss: 0.3656 - feature_loss: 0.8048 - val_loss: 1.1574 - val_output_loss: 0.3849 - val_feature_loss: 0.7726\n",
      "Epoch 78/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1742 - output_loss: 0.3697 - feature_loss: 0.8045\n",
      "Epoch 00078: val_output_loss did not improve from 0.35092\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1739 - output_loss: 0.3698 - feature_loss: 0.8041 - val_loss: 1.1467 - val_output_loss: 0.3704 - val_feature_loss: 0.7763\n",
      "Epoch 79/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1519 - output_loss: 0.3565 - feature_loss: 0.7953\n",
      "Epoch 00079: val_output_loss did not improve from 0.35092\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1509 - output_loss: 0.3563 - feature_loss: 0.7947 - val_loss: 1.0906 - val_output_loss: 0.3532 - val_feature_loss: 0.7374\n",
      "Epoch 80/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1341 - output_loss: 0.3492 - feature_loss: 0.7849\n",
      "Epoch 00080: val_output_loss improved from 0.35092 to 0.34892, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1346 - output_loss: 0.3498 - feature_loss: 0.7848 - val_loss: 1.1058 - val_output_loss: 0.3489 - val_feature_loss: 0.7569\n",
      "Epoch 81/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1475 - output_loss: 0.3522 - feature_loss: 0.7953\n",
      "Epoch 00081: val_output_loss improved from 0.34892 to 0.34340, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1468 - output_loss: 0.3521 - feature_loss: 0.7947 - val_loss: 1.0966 - val_output_loss: 0.3434 - val_feature_loss: 0.7532\n",
      "Epoch 82/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1101 - output_loss: 0.3347 - feature_loss: 0.7754\n",
      "Epoch 00082: val_output_loss did not improve from 0.34340\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1097 - output_loss: 0.3347 - feature_loss: 0.7750 - val_loss: 1.1088 - val_output_loss: 0.3565 - val_feature_loss: 0.7522\n",
      "Epoch 83/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1322 - output_loss: 0.3489 - feature_loss: 0.7833\n",
      "Epoch 00083: val_output_loss did not improve from 0.34340\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1326 - output_loss: 0.3493 - feature_loss: 0.7834 - val_loss: 1.1022 - val_output_loss: 0.3439 - val_feature_loss: 0.7583\n",
      "Epoch 84/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1355 - output_loss: 0.3500 - feature_loss: 0.7855\n",
      "Epoch 00084: val_output_loss improved from 0.34340 to 0.33683, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1348 - output_loss: 0.3499 - feature_loss: 0.7848 - val_loss: 1.0894 - val_output_loss: 0.3368 - val_feature_loss: 0.7526\n",
      "Epoch 85/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1025 - output_loss: 0.3293 - feature_loss: 0.7733\n",
      "Epoch 00085: val_output_loss did not improve from 0.33683\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.1031 - output_loss: 0.3300 - feature_loss: 0.7731 - val_loss: 1.1262 - val_output_loss: 0.3705 - val_feature_loss: 0.7557\n",
      "Epoch 86/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1131 - output_loss: 0.3357 - feature_loss: 0.7774\n",
      "Epoch 00086: val_output_loss improved from 0.33683 to 0.33583, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1138 - output_loss: 0.3361 - feature_loss: 0.7776 - val_loss: 1.0707 - val_output_loss: 0.3358 - val_feature_loss: 0.7349\n",
      "Epoch 87/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.1038 - output_loss: 0.3315 - feature_loss: 0.7723\n",
      "Epoch 00087: val_output_loss improved from 0.33583 to 0.32479, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.1039 - output_loss: 0.3319 - feature_loss: 0.7720 - val_loss: 1.0552 - val_output_loss: 0.3248 - val_feature_loss: 0.7304\n",
      "Epoch 88/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0715 - output_loss: 0.3135 - feature_loss: 0.7579\n",
      "Epoch 00088: val_output_loss did not improve from 0.32479\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0721 - output_loss: 0.3142 - feature_loss: 0.7579 - val_loss: 1.0645 - val_output_loss: 0.3352 - val_feature_loss: 0.7293\n",
      "Epoch 89/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0782 - output_loss: 0.3181 - feature_loss: 0.7602\n",
      "Epoch 00089: val_output_loss improved from 0.32479 to 0.32319, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0776 - output_loss: 0.3178 - feature_loss: 0.7598 - val_loss: 1.0467 - val_output_loss: 0.3232 - val_feature_loss: 0.7235\n",
      "Epoch 90/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0834 - output_loss: 0.3217 - feature_loss: 0.7616\n",
      "Epoch 00090: val_output_loss improved from 0.32319 to 0.30035, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0834 - output_loss: 0.3221 - feature_loss: 0.7614 - val_loss: 1.0162 - val_output_loss: 0.3003 - val_feature_loss: 0.7159\n",
      "Epoch 91/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0807 - output_loss: 0.3177 - feature_loss: 0.7631\n",
      "Epoch 00091: val_output_loss did not improve from 0.30035\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0809 - output_loss: 0.3180 - feature_loss: 0.7630 - val_loss: 1.0613 - val_output_loss: 0.3335 - val_feature_loss: 0.7279\n",
      "Epoch 92/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0857 - output_loss: 0.3208 - feature_loss: 0.7649\n",
      "Epoch 00092: val_output_loss improved from 0.30035 to 0.29540, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0851 - output_loss: 0.3207 - feature_loss: 0.7644 - val_loss: 1.0004 - val_output_loss: 0.2954 - val_feature_loss: 0.7050\n",
      "Epoch 93/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0515 - output_loss: 0.3022 - feature_loss: 0.7493\n",
      "Epoch 00093: val_output_loss did not improve from 0.29540\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0512 - output_loss: 0.3023 - feature_loss: 0.7489 - val_loss: 1.0081 - val_output_loss: 0.3007 - val_feature_loss: 0.7073\n",
      "Epoch 94/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0604 - output_loss: 0.3125 - feature_loss: 0.7478\n",
      "Epoch 00094: val_output_loss did not improve from 0.29540\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0596 - output_loss: 0.3123 - feature_loss: 0.7472 - val_loss: 1.0231 - val_output_loss: 0.3050 - val_feature_loss: 0.7181\n",
      "Epoch 95/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0424 - output_loss: 0.2993 - feature_loss: 0.7431\n",
      "Epoch 00095: val_output_loss did not improve from 0.29540\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0428 - output_loss: 0.3000 - feature_loss: 0.7428 - val_loss: 1.0164 - val_output_loss: 0.3093 - val_feature_loss: 0.7071\n",
      "Epoch 96/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0424 - output_loss: 0.2974 - feature_loss: 0.7450\n",
      "Epoch 00096: val_output_loss did not improve from 0.29540\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0423 - output_loss: 0.2977 - feature_loss: 0.7447 - val_loss: 1.0057 - val_output_loss: 0.3064 - val_feature_loss: 0.6993\n",
      "Epoch 97/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0210 - output_loss: 0.2881 - feature_loss: 0.7329\n",
      "Epoch 00097: val_output_loss did not improve from 0.29540\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0210 - output_loss: 0.2884 - feature_loss: 0.7325 - val_loss: 1.0113 - val_output_loss: 0.3010 - val_feature_loss: 0.7102\n",
      "Epoch 98/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0336 - output_loss: 0.2975 - feature_loss: 0.7361\n",
      "Epoch 00098: val_output_loss improved from 0.29540 to 0.29199, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0334 - output_loss: 0.2977 - feature_loss: 0.7357 - val_loss: 0.9881 - val_output_loss: 0.2920 - val_feature_loss: 0.6962\n",
      "Epoch 99/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0115 - output_loss: 0.2873 - feature_loss: 0.7242\n",
      "Epoch 00099: val_output_loss improved from 0.29199 to 0.27778, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0105 - output_loss: 0.2871 - feature_loss: 0.7234 - val_loss: 0.9607 - val_output_loss: 0.2778 - val_feature_loss: 0.6829\n",
      "Epoch 100/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0172 - output_loss: 0.2883 - feature_loss: 0.7289\n",
      "Epoch 00100: val_output_loss did not improve from 0.27778\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0171 - output_loss: 0.2887 - feature_loss: 0.7284 - val_loss: 0.9950 - val_output_loss: 0.2925 - val_feature_loss: 0.7025\n",
      "Epoch 101/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0223 - output_loss: 0.2912 - feature_loss: 0.7311\n",
      "Epoch 00101: val_output_loss did not improve from 0.27778\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0224 - output_loss: 0.2914 - feature_loss: 0.7310 - val_loss: 1.0006 - val_output_loss: 0.3110 - val_feature_loss: 0.6896\n",
      "Epoch 102/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0155 - output_loss: 0.2869 - feature_loss: 0.7286\n",
      "Epoch 00102: val_output_loss improved from 0.27778 to 0.27247, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0157 - output_loss: 0.2873 - feature_loss: 0.7284 - val_loss: 0.9530 - val_output_loss: 0.2725 - val_feature_loss: 0.6805\n",
      "Epoch 103/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0090 - output_loss: 0.2857 - feature_loss: 0.7233\n",
      "Epoch 00103: val_output_loss did not improve from 0.27247\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0088 - output_loss: 0.2856 - feature_loss: 0.7232 - val_loss: 0.9825 - val_output_loss: 0.2903 - val_feature_loss: 0.6922\n",
      "Epoch 104/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 1.0111 - output_loss: 0.2874 - feature_loss: 0.7236\n",
      "Epoch 00104: val_output_loss did not improve from 0.27247\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 1.0105 - output_loss: 0.2872 - feature_loss: 0.7233 - val_loss: 0.9761 - val_output_loss: 0.2807 - val_feature_loss: 0.6954\n",
      "Epoch 105/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9844 - output_loss: 0.2730 - feature_loss: 0.7114\n",
      "Epoch 00105: val_output_loss did not improve from 0.27247\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9836 - output_loss: 0.2728 - feature_loss: 0.7108 - val_loss: 0.9636 - val_output_loss: 0.2834 - val_feature_loss: 0.6802\n",
      "Epoch 106/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9896 - output_loss: 0.2770 - feature_loss: 0.7125\n",
      "Epoch 00106: val_output_loss did not improve from 0.27247\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9893 - output_loss: 0.2772 - feature_loss: 0.7121 - val_loss: 0.9819 - val_output_loss: 0.2846 - val_feature_loss: 0.6973\n",
      "Epoch 107/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9822 - output_loss: 0.2700 - feature_loss: 0.7122\n",
      "Epoch 00107: val_output_loss did not improve from 0.27247\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9820 - output_loss: 0.2705 - feature_loss: 0.7115 - val_loss: 1.0091 - val_output_loss: 0.3063 - val_feature_loss: 0.7029\n",
      "Epoch 108/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9871 - output_loss: 0.2754 - feature_loss: 0.7118\n",
      "Epoch 00108: val_output_loss improved from 0.27247 to 0.27071, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9879 - output_loss: 0.2761 - feature_loss: 0.7117 - val_loss: 0.9476 - val_output_loss: 0.2707 - val_feature_loss: 0.6769\n",
      "Epoch 109/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9851 - output_loss: 0.2748 - feature_loss: 0.7103\n",
      "Epoch 00109: val_output_loss did not improve from 0.27071\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9847 - output_loss: 0.2748 - feature_loss: 0.7099 - val_loss: 0.9727 - val_output_loss: 0.2854 - val_feature_loss: 0.6873\n",
      "Epoch 110/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9895 - output_loss: 0.2742 - feature_loss: 0.7153\n",
      "Epoch 00110: val_output_loss improved from 0.27071 to 0.26601, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9893 - output_loss: 0.2743 - feature_loss: 0.7150 - val_loss: 0.9280 - val_output_loss: 0.2660 - val_feature_loss: 0.6620\n",
      "Epoch 111/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9780 - output_loss: 0.2723 - feature_loss: 0.7057\n",
      "Epoch 00111: val_output_loss did not improve from 0.26601\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9781 - output_loss: 0.2724 - feature_loss: 0.7057 - val_loss: 0.9470 - val_output_loss: 0.2707 - val_feature_loss: 0.6763\n",
      "Epoch 112/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9783 - output_loss: 0.2698 - feature_loss: 0.7086\n",
      "Epoch 00112: val_output_loss did not improve from 0.26601\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9787 - output_loss: 0.2700 - feature_loss: 0.7087 - val_loss: 0.9222 - val_output_loss: 0.2660 - val_feature_loss: 0.6562\n",
      "Epoch 113/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9541 - output_loss: 0.2599 - feature_loss: 0.6941\n",
      "Epoch 00113: val_output_loss did not improve from 0.26601\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9549 - output_loss: 0.2603 - feature_loss: 0.6946 - val_loss: 0.9784 - val_output_loss: 0.2816 - val_feature_loss: 0.6968\n",
      "Epoch 114/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9675 - output_loss: 0.2667 - feature_loss: 0.7008\n",
      "Epoch 00114: val_output_loss did not improve from 0.26601\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9671 - output_loss: 0.2667 - feature_loss: 0.7005 - val_loss: 0.9551 - val_output_loss: 0.2748 - val_feature_loss: 0.6803\n",
      "Epoch 115/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9632 - output_loss: 0.2638 - feature_loss: 0.6994\n",
      "Epoch 00115: val_output_loss improved from 0.26601 to 0.24924, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9625 - output_loss: 0.2636 - feature_loss: 0.6990 - val_loss: 0.9113 - val_output_loss: 0.2492 - val_feature_loss: 0.6621\n",
      "Epoch 116/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9486 - output_loss: 0.2593 - feature_loss: 0.6893\n",
      "Epoch 00116: val_output_loss did not improve from 0.24924\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9484 - output_loss: 0.2595 - feature_loss: 0.6889 - val_loss: 0.9617 - val_output_loss: 0.2734 - val_feature_loss: 0.6883\n",
      "Epoch 117/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9457 - output_loss: 0.2586 - feature_loss: 0.6871\n",
      "Epoch 00117: val_output_loss did not improve from 0.24924\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9457 - output_loss: 0.2589 - feature_loss: 0.6867 - val_loss: 0.9451 - val_output_loss: 0.2698 - val_feature_loss: 0.6752\n",
      "Epoch 118/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9373 - output_loss: 0.2557 - feature_loss: 0.6816\n",
      "Epoch 00118: val_output_loss did not improve from 0.24924\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9373 - output_loss: 0.2557 - feature_loss: 0.6815 - val_loss: 0.9020 - val_output_loss: 0.2559 - val_feature_loss: 0.6461\n",
      "Epoch 119/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9504 - output_loss: 0.2596 - feature_loss: 0.6909\n",
      "Epoch 00119: val_output_loss did not improve from 0.24924\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9494 - output_loss: 0.2592 - feature_loss: 0.6902 - val_loss: 0.9676 - val_output_loss: 0.2962 - val_feature_loss: 0.6714\n",
      "Epoch 120/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9324 - output_loss: 0.2529 - feature_loss: 0.6795\n",
      "Epoch 00120: val_output_loss improved from 0.24924 to 0.24371, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9317 - output_loss: 0.2527 - feature_loss: 0.6791 - val_loss: 0.8777 - val_output_loss: 0.2437 - val_feature_loss: 0.6340\n",
      "Epoch 121/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9151 - output_loss: 0.2450 - feature_loss: 0.6701\n",
      "Epoch 00121: val_output_loss improved from 0.24371 to 0.24252, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9159 - output_loss: 0.2457 - feature_loss: 0.6701 - val_loss: 0.8686 - val_output_loss: 0.2425 - val_feature_loss: 0.6261\n",
      "Epoch 122/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9257 - output_loss: 0.2516 - feature_loss: 0.6741\n",
      "Epoch 00122: val_output_loss improved from 0.24252 to 0.23563, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9253 - output_loss: 0.2516 - feature_loss: 0.6737 - val_loss: 0.8661 - val_output_loss: 0.2356 - val_feature_loss: 0.6305\n",
      "Epoch 123/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9268 - output_loss: 0.2495 - feature_loss: 0.6773\n",
      "Epoch 00123: val_output_loss did not improve from 0.23563\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9264 - output_loss: 0.2495 - feature_loss: 0.6770 - val_loss: 0.9179 - val_output_loss: 0.2543 - val_feature_loss: 0.6635\n",
      "Epoch 124/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8969 - output_loss: 0.2369 - feature_loss: 0.6600\n",
      "Epoch 00124: val_output_loss did not improve from 0.23563\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8965 - output_loss: 0.2368 - feature_loss: 0.6597 - val_loss: 0.8964 - val_output_loss: 0.2547 - val_feature_loss: 0.6417\n",
      "Epoch 125/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9141 - output_loss: 0.2477 - feature_loss: 0.6663\n",
      "Epoch 00125: val_output_loss did not improve from 0.23563\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9139 - output_loss: 0.2480 - feature_loss: 0.6660 - val_loss: 0.8822 - val_output_loss: 0.2474 - val_feature_loss: 0.6347\n",
      "Epoch 126/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9151 - output_loss: 0.2471 - feature_loss: 0.6680\n",
      "Epoch 00126: val_output_loss did not improve from 0.23563\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9151 - output_loss: 0.2472 - feature_loss: 0.6679 - val_loss: 0.9333 - val_output_loss: 0.2671 - val_feature_loss: 0.6663\n",
      "Epoch 127/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9111 - output_loss: 0.2436 - feature_loss: 0.6674\n",
      "Epoch 00127: val_output_loss did not improve from 0.23563\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9118 - output_loss: 0.2442 - feature_loss: 0.6676 - val_loss: 0.8866 - val_output_loss: 0.2515 - val_feature_loss: 0.6351\n",
      "Epoch 128/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9166 - output_loss: 0.2475 - feature_loss: 0.6691\n",
      "Epoch 00128: val_output_loss improved from 0.23563 to 0.23523, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.9159 - output_loss: 0.2476 - feature_loss: 0.6683 - val_loss: 0.8537 - val_output_loss: 0.2352 - val_feature_loss: 0.6185\n",
      "Epoch 129/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.9082 - output_loss: 0.2454 - feature_loss: 0.6628\n",
      "Epoch 00129: val_output_loss improved from 0.23523 to 0.23025, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.9077 - output_loss: 0.2454 - feature_loss: 0.6623 - val_loss: 0.8486 - val_output_loss: 0.2302 - val_feature_loss: 0.6183\n",
      "Epoch 130/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8977 - output_loss: 0.2411 - feature_loss: 0.6566\n",
      "Epoch 00130: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8964 - output_loss: 0.2407 - feature_loss: 0.6557 - val_loss: 0.8687 - val_output_loss: 0.2483 - val_feature_loss: 0.6204\n",
      "Epoch 131/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8996 - output_loss: 0.2420 - feature_loss: 0.6576\n",
      "Epoch 00131: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8999 - output_loss: 0.2423 - feature_loss: 0.6576 - val_loss: 0.8585 - val_output_loss: 0.2427 - val_feature_loss: 0.6158\n",
      "Epoch 132/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8768 - output_loss: 0.2323 - feature_loss: 0.6446\n",
      "Epoch 00132: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8768 - output_loss: 0.2324 - feature_loss: 0.6444 - val_loss: 0.8672 - val_output_loss: 0.2428 - val_feature_loss: 0.6245\n",
      "Epoch 133/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8891 - output_loss: 0.2419 - feature_loss: 0.6472\n",
      "Epoch 00133: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8893 - output_loss: 0.2419 - feature_loss: 0.6473 - val_loss: 0.9889 - val_output_loss: 0.2992 - val_feature_loss: 0.6897\n",
      "Epoch 134/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8986 - output_loss: 0.2459 - feature_loss: 0.6527\n",
      "Epoch 00134: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8976 - output_loss: 0.2459 - feature_loss: 0.6518 - val_loss: 0.8710 - val_output_loss: 0.2498 - val_feature_loss: 0.6211\n",
      "Epoch 135/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8894 - output_loss: 0.2377 - feature_loss: 0.6517\n",
      "Epoch 00135: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8893 - output_loss: 0.2377 - feature_loss: 0.6517 - val_loss: 0.9191 - val_output_loss: 0.2734 - val_feature_loss: 0.6457\n",
      "Epoch 136/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8731 - output_loss: 0.2317 - feature_loss: 0.6414\n",
      "Epoch 00136: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8721 - output_loss: 0.2314 - feature_loss: 0.6407 - val_loss: 0.8669 - val_output_loss: 0.2391 - val_feature_loss: 0.6277\n",
      "Epoch 137/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8773 - output_loss: 0.2303 - feature_loss: 0.6470\n",
      "Epoch 00137: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8778 - output_loss: 0.2307 - feature_loss: 0.6471 - val_loss: 0.8715 - val_output_loss: 0.2442 - val_feature_loss: 0.6273\n",
      "Epoch 138/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8856 - output_loss: 0.2335 - feature_loss: 0.6521\n",
      "Epoch 00138: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8845 - output_loss: 0.2331 - feature_loss: 0.6514 - val_loss: 0.8464 - val_output_loss: 0.2353 - val_feature_loss: 0.6111\n",
      "Epoch 139/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8747 - output_loss: 0.2341 - feature_loss: 0.6406\n",
      "Epoch 00139: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8751 - output_loss: 0.2344 - feature_loss: 0.6406 - val_loss: 0.8561 - val_output_loss: 0.2423 - val_feature_loss: 0.6138\n",
      "Epoch 140/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8780 - output_loss: 0.2348 - feature_loss: 0.6433\n",
      "Epoch 00140: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8785 - output_loss: 0.2352 - feature_loss: 0.6433 - val_loss: 0.9037 - val_output_loss: 0.2634 - val_feature_loss: 0.6403\n",
      "Epoch 141/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8652 - output_loss: 0.2249 - feature_loss: 0.6403\n",
      "Epoch 00141: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8645 - output_loss: 0.2248 - feature_loss: 0.6398 - val_loss: 0.8741 - val_output_loss: 0.2436 - val_feature_loss: 0.6304\n",
      "Epoch 142/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8687 - output_loss: 0.2321 - feature_loss: 0.6366\n",
      "Epoch 00142: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8683 - output_loss: 0.2323 - feature_loss: 0.6360 - val_loss: 0.8687 - val_output_loss: 0.2356 - val_feature_loss: 0.6330\n",
      "Epoch 143/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8669 - output_loss: 0.2299 - feature_loss: 0.6369\n",
      "Epoch 00143: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8665 - output_loss: 0.2297 - feature_loss: 0.6368 - val_loss: 0.8317 - val_output_loss: 0.2328 - val_feature_loss: 0.5989\n",
      "Epoch 144/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8583 - output_loss: 0.2229 - feature_loss: 0.6354\n",
      "Epoch 00144: val_output_loss did not improve from 0.23025\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8580 - output_loss: 0.2231 - feature_loss: 0.6349 - val_loss: 0.8623 - val_output_loss: 0.2420 - val_feature_loss: 0.6203\n",
      "Epoch 145/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8717 - output_loss: 0.2294 - feature_loss: 0.6422\n",
      "Epoch 00145: val_output_loss improved from 0.23025 to 0.22910, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.8718 - output_loss: 0.2297 - feature_loss: 0.6421 - val_loss: 0.8459 - val_output_loss: 0.2291 - val_feature_loss: 0.6168\n",
      "Epoch 146/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8590 - output_loss: 0.2239 - feature_loss: 0.6351\n",
      "Epoch 00146: val_output_loss did not improve from 0.22910\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8594 - output_loss: 0.2243 - feature_loss: 0.6351 - val_loss: 0.9439 - val_output_loss: 0.2856 - val_feature_loss: 0.6583\n",
      "Epoch 147/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8383 - output_loss: 0.2170 - feature_loss: 0.6213\n",
      "Epoch 00147: val_output_loss did not improve from 0.22910\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8379 - output_loss: 0.2171 - feature_loss: 0.6208 - val_loss: 0.8748 - val_output_loss: 0.2456 - val_feature_loss: 0.6293\n",
      "Epoch 148/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8431 - output_loss: 0.2170 - feature_loss: 0.6261\n",
      "Epoch 00148: val_output_loss did not improve from 0.22910\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8435 - output_loss: 0.2176 - feature_loss: 0.6259 - val_loss: 0.8422 - val_output_loss: 0.2300 - val_feature_loss: 0.6122\n",
      "Epoch 149/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8421 - output_loss: 0.2173 - feature_loss: 0.6247\n",
      "Epoch 00149: val_output_loss did not improve from 0.22910\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8411 - output_loss: 0.2171 - feature_loss: 0.6240 - val_loss: 0.8310 - val_output_loss: 0.2310 - val_feature_loss: 0.6000\n",
      "Epoch 150/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8550 - output_loss: 0.2253 - feature_loss: 0.6296\n",
      "Epoch 00150: val_output_loss improved from 0.22910 to 0.21854, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.8547 - output_loss: 0.2255 - feature_loss: 0.6291 - val_loss: 0.8229 - val_output_loss: 0.2185 - val_feature_loss: 0.6044\n",
      "Epoch 151/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8551 - output_loss: 0.2215 - feature_loss: 0.6336\n",
      "Epoch 00151: val_output_loss did not improve from 0.21854\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8551 - output_loss: 0.2217 - feature_loss: 0.6335 - val_loss: 0.9258 - val_output_loss: 0.2699 - val_feature_loss: 0.6558\n",
      "Epoch 152/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8447 - output_loss: 0.2164 - feature_loss: 0.6283\n",
      "Epoch 00152: val_output_loss did not improve from 0.21854\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8460 - output_loss: 0.2173 - feature_loss: 0.6287 - val_loss: 0.8312 - val_output_loss: 0.2407 - val_feature_loss: 0.5906\n",
      "Epoch 153/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8355 - output_loss: 0.2161 - feature_loss: 0.6195\n",
      "Epoch 00153: val_output_loss did not improve from 0.21854\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8348 - output_loss: 0.2158 - feature_loss: 0.6190 - val_loss: 0.8221 - val_output_loss: 0.2186 - val_feature_loss: 0.6036\n",
      "Epoch 154/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8388 - output_loss: 0.2191 - feature_loss: 0.6197\n",
      "Epoch 00154: val_output_loss did not improve from 0.21854\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8383 - output_loss: 0.2192 - feature_loss: 0.6192 - val_loss: 0.8480 - val_output_loss: 0.2342 - val_feature_loss: 0.6137\n",
      "Epoch 155/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8570 - output_loss: 0.2267 - feature_loss: 0.6303\n",
      "Epoch 00155: val_output_loss did not improve from 0.21854\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8571 - output_loss: 0.2268 - feature_loss: 0.6303 - val_loss: 0.8119 - val_output_loss: 0.2236 - val_feature_loss: 0.5882\n",
      "Epoch 156/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8363 - output_loss: 0.2195 - feature_loss: 0.6168\n",
      "Epoch 00156: val_output_loss improved from 0.21854 to 0.18781, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.8352 - output_loss: 0.2192 - feature_loss: 0.6160 - val_loss: 0.7550 - val_output_loss: 0.1878 - val_feature_loss: 0.5672\n",
      "Epoch 157/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8094 - output_loss: 0.2064 - feature_loss: 0.6030\n",
      "Epoch 00157: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8103 - output_loss: 0.2071 - feature_loss: 0.6032 - val_loss: 0.8055 - val_output_loss: 0.2175 - val_feature_loss: 0.5880\n",
      "Epoch 158/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8199 - output_loss: 0.2104 - feature_loss: 0.6096\n",
      "Epoch 00158: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8192 - output_loss: 0.2100 - feature_loss: 0.6091 - val_loss: 0.7886 - val_output_loss: 0.2175 - val_feature_loss: 0.5710\n",
      "Epoch 159/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8086 - output_loss: 0.2057 - feature_loss: 0.6029\n",
      "Epoch 00159: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8073 - output_loss: 0.2054 - feature_loss: 0.6019 - val_loss: 0.8020 - val_output_loss: 0.2149 - val_feature_loss: 0.5871\n",
      "Epoch 160/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8240 - output_loss: 0.2119 - feature_loss: 0.6121\n",
      "Epoch 00160: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8231 - output_loss: 0.2119 - feature_loss: 0.6112 - val_loss: 0.8272 - val_output_loss: 0.2348 - val_feature_loss: 0.5924\n",
      "Epoch 161/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8191 - output_loss: 0.2101 - feature_loss: 0.6090\n",
      "Epoch 00161: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8189 - output_loss: 0.2101 - feature_loss: 0.6088 - val_loss: 0.7782 - val_output_loss: 0.2088 - val_feature_loss: 0.5694\n",
      "Epoch 162/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8321 - output_loss: 0.2181 - feature_loss: 0.6140\n",
      "Epoch 00162: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8330 - output_loss: 0.2185 - feature_loss: 0.6145 - val_loss: 0.8255 - val_output_loss: 0.2292 - val_feature_loss: 0.5964\n",
      "Epoch 163/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8027 - output_loss: 0.2073 - feature_loss: 0.5954\n",
      "Epoch 00163: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8041 - output_loss: 0.2082 - feature_loss: 0.5959 - val_loss: 0.8857 - val_output_loss: 0.2602 - val_feature_loss: 0.6255\n",
      "Epoch 164/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7978 - output_loss: 0.2053 - feature_loss: 0.5925\n",
      "Epoch 00164: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7968 - output_loss: 0.2050 - feature_loss: 0.5918 - val_loss: 0.8562 - val_output_loss: 0.2441 - val_feature_loss: 0.6121\n",
      "Epoch 165/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7828 - output_loss: 0.1985 - feature_loss: 0.5843\n",
      "Epoch 00165: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7821 - output_loss: 0.1983 - feature_loss: 0.5838 - val_loss: 0.8127 - val_output_loss: 0.2168 - val_feature_loss: 0.5959\n",
      "Epoch 166/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8135 - output_loss: 0.2095 - feature_loss: 0.6040\n",
      "Epoch 00166: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8128 - output_loss: 0.2096 - feature_loss: 0.6032 - val_loss: 0.7699 - val_output_loss: 0.2022 - val_feature_loss: 0.5677\n",
      "Epoch 167/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7978 - output_loss: 0.2041 - feature_loss: 0.5937\n",
      "Epoch 00167: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7984 - output_loss: 0.2046 - feature_loss: 0.5939 - val_loss: 0.8031 - val_output_loss: 0.2267 - val_feature_loss: 0.5764\n",
      "Epoch 168/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7962 - output_loss: 0.2062 - feature_loss: 0.5900\n",
      "Epoch 00168: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7973 - output_loss: 0.2070 - feature_loss: 0.5903 - val_loss: 0.7790 - val_output_loss: 0.2070 - val_feature_loss: 0.5720\n",
      "Epoch 169/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7946 - output_loss: 0.2043 - feature_loss: 0.5903\n",
      "Epoch 00169: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7944 - output_loss: 0.2044 - feature_loss: 0.5900 - val_loss: 0.7834 - val_output_loss: 0.2075 - val_feature_loss: 0.5759\n",
      "Epoch 170/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7899 - output_loss: 0.2015 - feature_loss: 0.5884\n",
      "Epoch 00170: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7893 - output_loss: 0.2013 - feature_loss: 0.5880 - val_loss: 0.7661 - val_output_loss: 0.2004 - val_feature_loss: 0.5657\n",
      "Epoch 171/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7881 - output_loss: 0.2011 - feature_loss: 0.5870\n",
      "Epoch 00171: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7882 - output_loss: 0.2011 - feature_loss: 0.5870 - val_loss: 0.8211 - val_output_loss: 0.2172 - val_feature_loss: 0.6039\n",
      "Epoch 172/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8097 - output_loss: 0.2101 - feature_loss: 0.5997\n",
      "Epoch 00172: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8086 - output_loss: 0.2097 - feature_loss: 0.5989 - val_loss: 0.7654 - val_output_loss: 0.2084 - val_feature_loss: 0.5570\n",
      "Epoch 173/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7856 - output_loss: 0.1999 - feature_loss: 0.5857\n",
      "Epoch 00173: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7856 - output_loss: 0.2003 - feature_loss: 0.5854 - val_loss: 0.7531 - val_output_loss: 0.2062 - val_feature_loss: 0.5469\n",
      "Epoch 174/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7612 - output_loss: 0.1894 - feature_loss: 0.5718\n",
      "Epoch 00174: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7609 - output_loss: 0.1897 - feature_loss: 0.5712 - val_loss: 0.7975 - val_output_loss: 0.2177 - val_feature_loss: 0.5799\n",
      "Epoch 175/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.8032 - output_loss: 0.2063 - feature_loss: 0.5969\n",
      "Epoch 00175: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.8027 - output_loss: 0.2062 - feature_loss: 0.5965 - val_loss: 0.7925 - val_output_loss: 0.2174 - val_feature_loss: 0.5751\n",
      "Epoch 176/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7861 - output_loss: 0.2012 - feature_loss: 0.5848\n",
      "Epoch 00176: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7858 - output_loss: 0.2016 - feature_loss: 0.5842 - val_loss: 0.7773 - val_output_loss: 0.2101 - val_feature_loss: 0.5672\n",
      "Epoch 177/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7677 - output_loss: 0.1936 - feature_loss: 0.5741\n",
      "Epoch 00177: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7687 - output_loss: 0.1943 - feature_loss: 0.5744 - val_loss: 0.7559 - val_output_loss: 0.1977 - val_feature_loss: 0.5582\n",
      "Epoch 178/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7776 - output_loss: 0.1967 - feature_loss: 0.5809\n",
      "Epoch 00178: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7774 - output_loss: 0.1966 - feature_loss: 0.5809 - val_loss: 0.7819 - val_output_loss: 0.2167 - val_feature_loss: 0.5652\n",
      "Epoch 179/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7970 - output_loss: 0.2076 - feature_loss: 0.5894\n",
      "Epoch 00179: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7962 - output_loss: 0.2076 - feature_loss: 0.5885 - val_loss: 0.7831 - val_output_loss: 0.2056 - val_feature_loss: 0.5775\n",
      "Epoch 180/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7600 - output_loss: 0.1873 - feature_loss: 0.5727\n",
      "Epoch 00180: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7600 - output_loss: 0.1876 - feature_loss: 0.5725 - val_loss: 0.7960 - val_output_loss: 0.2146 - val_feature_loss: 0.5814\n",
      "Epoch 181/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7623 - output_loss: 0.1911 - feature_loss: 0.5712\n",
      "Epoch 00181: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7623 - output_loss: 0.1910 - feature_loss: 0.5712 - val_loss: 0.7540 - val_output_loss: 0.2033 - val_feature_loss: 0.5507\n",
      "Epoch 182/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7650 - output_loss: 0.1906 - feature_loss: 0.5744\n",
      "Epoch 00182: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7638 - output_loss: 0.1901 - feature_loss: 0.5737 - val_loss: 0.7582 - val_output_loss: 0.2030 - val_feature_loss: 0.5552\n",
      "Epoch 183/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7784 - output_loss: 0.2005 - feature_loss: 0.5779\n",
      "Epoch 00183: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7786 - output_loss: 0.2005 - feature_loss: 0.5781 - val_loss: 0.7621 - val_output_loss: 0.2079 - val_feature_loss: 0.5542\n",
      "Epoch 184/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7599 - output_loss: 0.1911 - feature_loss: 0.5688\n",
      "Epoch 00184: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7595 - output_loss: 0.1911 - feature_loss: 0.5685 - val_loss: 0.7509 - val_output_loss: 0.1969 - val_feature_loss: 0.5540\n",
      "Epoch 185/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7474 - output_loss: 0.1853 - feature_loss: 0.5621\n",
      "Epoch 00185: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7474 - output_loss: 0.1856 - feature_loss: 0.5619 - val_loss: 0.7729 - val_output_loss: 0.2036 - val_feature_loss: 0.5693\n",
      "Epoch 186/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7547 - output_loss: 0.1892 - feature_loss: 0.5655\n",
      "Epoch 00186: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7539 - output_loss: 0.1890 - feature_loss: 0.5650 - val_loss: 0.7287 - val_output_loss: 0.1966 - val_feature_loss: 0.5320\n",
      "Epoch 187/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7587 - output_loss: 0.1909 - feature_loss: 0.5678\n",
      "Epoch 00187: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7585 - output_loss: 0.1912 - feature_loss: 0.5673 - val_loss: 0.7066 - val_output_loss: 0.1882 - val_feature_loss: 0.5184\n",
      "Epoch 188/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7606 - output_loss: 0.1922 - feature_loss: 0.5684\n",
      "Epoch 00188: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7606 - output_loss: 0.1925 - feature_loss: 0.5680 - val_loss: 0.7364 - val_output_loss: 0.1995 - val_feature_loss: 0.5369\n",
      "Epoch 189/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7578 - output_loss: 0.1899 - feature_loss: 0.5679\n",
      "Epoch 00189: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7567 - output_loss: 0.1896 - feature_loss: 0.5672 - val_loss: 0.7794 - val_output_loss: 0.2160 - val_feature_loss: 0.5634\n",
      "Epoch 190/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7588 - output_loss: 0.1910 - feature_loss: 0.5679\n",
      "Epoch 00190: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7586 - output_loss: 0.1908 - feature_loss: 0.5677 - val_loss: 0.7522 - val_output_loss: 0.1949 - val_feature_loss: 0.5573\n",
      "Epoch 191/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7558 - output_loss: 0.1901 - feature_loss: 0.5657\n",
      "Epoch 00191: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7552 - output_loss: 0.1902 - feature_loss: 0.5650 - val_loss: 0.7858 - val_output_loss: 0.2173 - val_feature_loss: 0.5685\n",
      "Epoch 192/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7501 - output_loss: 0.1896 - feature_loss: 0.5605\n",
      "Epoch 00192: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7498 - output_loss: 0.1896 - feature_loss: 0.5602 - val_loss: 0.7365 - val_output_loss: 0.2013 - val_feature_loss: 0.5352\n",
      "Epoch 193/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7324 - output_loss: 0.1807 - feature_loss: 0.5517\n",
      "Epoch 00193: val_output_loss did not improve from 0.18781\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7320 - output_loss: 0.1807 - feature_loss: 0.5513 - val_loss: 0.7738 - val_output_loss: 0.2092 - val_feature_loss: 0.5645\n",
      "Epoch 194/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7442 - output_loss: 0.1877 - feature_loss: 0.5565\n",
      "Epoch 00194: val_output_loss improved from 0.18781 to 0.17881, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7430 - output_loss: 0.1873 - feature_loss: 0.5558 - val_loss: 0.6781 - val_output_loss: 0.1788 - val_feature_loss: 0.4993\n",
      "Epoch 195/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7232 - output_loss: 0.1763 - feature_loss: 0.5469\n",
      "Epoch 00195: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7235 - output_loss: 0.1768 - feature_loss: 0.5467 - val_loss: 0.6884 - val_output_loss: 0.1824 - val_feature_loss: 0.5060\n",
      "Epoch 196/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7380 - output_loss: 0.1846 - feature_loss: 0.5534\n",
      "Epoch 00196: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7382 - output_loss: 0.1850 - feature_loss: 0.5533 - val_loss: 0.7067 - val_output_loss: 0.1873 - val_feature_loss: 0.5193\n",
      "Epoch 197/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7497 - output_loss: 0.1851 - feature_loss: 0.5646\n",
      "Epoch 00197: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7495 - output_loss: 0.1853 - feature_loss: 0.5642 - val_loss: 0.7858 - val_output_loss: 0.2291 - val_feature_loss: 0.5568\n",
      "Epoch 198/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7456 - output_loss: 0.1874 - feature_loss: 0.5581\n",
      "Epoch 00198: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7451 - output_loss: 0.1874 - feature_loss: 0.5577 - val_loss: 0.7545 - val_output_loss: 0.2050 - val_feature_loss: 0.5495\n",
      "Epoch 199/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7242 - output_loss: 0.1796 - feature_loss: 0.5446\n",
      "Epoch 00199: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7232 - output_loss: 0.1793 - feature_loss: 0.5439 - val_loss: 0.6865 - val_output_loss: 0.1814 - val_feature_loss: 0.5051\n",
      "Epoch 200/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7414 - output_loss: 0.1814 - feature_loss: 0.5600\n",
      "Epoch 00200: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7416 - output_loss: 0.1817 - feature_loss: 0.5599 - val_loss: 0.7690 - val_output_loss: 0.2128 - val_feature_loss: 0.5562\n",
      "Epoch 201/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7386 - output_loss: 0.1845 - feature_loss: 0.5541\n",
      "Epoch 00201: val_output_loss did not improve from 0.17881\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7391 - output_loss: 0.1850 - feature_loss: 0.5541 - val_loss: 0.8492 - val_output_loss: 0.2454 - val_feature_loss: 0.6038\n",
      "Epoch 202/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7316 - output_loss: 0.1828 - feature_loss: 0.5488\n",
      "Epoch 00202: val_output_loss improved from 0.17881 to 0.17600, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7317 - output_loss: 0.1832 - feature_loss: 0.5485 - val_loss: 0.6978 - val_output_loss: 0.1760 - val_feature_loss: 0.5218\n",
      "Epoch 203/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7392 - output_loss: 0.1874 - feature_loss: 0.5517\n",
      "Epoch 00203: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7394 - output_loss: 0.1878 - feature_loss: 0.5516 - val_loss: 0.6862 - val_output_loss: 0.1820 - val_feature_loss: 0.5042\n",
      "Epoch 204/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7172 - output_loss: 0.1773 - feature_loss: 0.5399\n",
      "Epoch 00204: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7173 - output_loss: 0.1777 - feature_loss: 0.5396 - val_loss: 0.7434 - val_output_loss: 0.1891 - val_feature_loss: 0.5543\n",
      "Epoch 205/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7203 - output_loss: 0.1800 - feature_loss: 0.5403\n",
      "Epoch 00205: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7194 - output_loss: 0.1797 - feature_loss: 0.5397 - val_loss: 0.6816 - val_output_loss: 0.1825 - val_feature_loss: 0.4991\n",
      "Epoch 206/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7227 - output_loss: 0.1764 - feature_loss: 0.5464\n",
      "Epoch 00206: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7225 - output_loss: 0.1766 - feature_loss: 0.5459 - val_loss: 0.6781 - val_output_loss: 0.1828 - val_feature_loss: 0.4953\n",
      "Epoch 207/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6958 - output_loss: 0.1667 - feature_loss: 0.5291\n",
      "Epoch 00207: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6951 - output_loss: 0.1666 - feature_loss: 0.5285 - val_loss: 0.7078 - val_output_loss: 0.1815 - val_feature_loss: 0.5263\n",
      "Epoch 208/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7148 - output_loss: 0.1735 - feature_loss: 0.5413\n",
      "Epoch 00208: val_output_loss did not improve from 0.17600\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7147 - output_loss: 0.1735 - feature_loss: 0.5411 - val_loss: 0.7069 - val_output_loss: 0.1864 - val_feature_loss: 0.5204\n",
      "Epoch 209/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7161 - output_loss: 0.1752 - feature_loss: 0.5409\n",
      "Epoch 00209: val_output_loss improved from 0.17600 to 0.16383, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7167 - output_loss: 0.1756 - feature_loss: 0.5410 - val_loss: 0.6835 - val_output_loss: 0.1638 - val_feature_loss: 0.5196\n",
      "Epoch 210/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7032 - output_loss: 0.1733 - feature_loss: 0.5299\n",
      "Epoch 00210: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7024 - output_loss: 0.1731 - feature_loss: 0.5293 - val_loss: 0.7021 - val_output_loss: 0.1775 - val_feature_loss: 0.5246\n",
      "Epoch 211/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6991 - output_loss: 0.1670 - feature_loss: 0.5322\n",
      "Epoch 00211: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6988 - output_loss: 0.1671 - feature_loss: 0.5317 - val_loss: 0.7376 - val_output_loss: 0.1955 - val_feature_loss: 0.5420\n",
      "Epoch 212/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7082 - output_loss: 0.1745 - feature_loss: 0.5337\n",
      "Epoch 00212: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7083 - output_loss: 0.1748 - feature_loss: 0.5335 - val_loss: 0.7393 - val_output_loss: 0.1946 - val_feature_loss: 0.5447\n",
      "Epoch 213/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7083 - output_loss: 0.1736 - feature_loss: 0.5347\n",
      "Epoch 00213: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7077 - output_loss: 0.1736 - feature_loss: 0.5341 - val_loss: 0.6798 - val_output_loss: 0.1648 - val_feature_loss: 0.5150\n",
      "Epoch 214/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7283 - output_loss: 0.1801 - feature_loss: 0.5481\n",
      "Epoch 00214: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7285 - output_loss: 0.1802 - feature_loss: 0.5482 - val_loss: 0.7286 - val_output_loss: 0.1926 - val_feature_loss: 0.5360\n",
      "Epoch 215/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7254 - output_loss: 0.1803 - feature_loss: 0.5451\n",
      "Epoch 00215: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7266 - output_loss: 0.1811 - feature_loss: 0.5455 - val_loss: 0.7180 - val_output_loss: 0.1824 - val_feature_loss: 0.5356\n",
      "Epoch 216/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7272 - output_loss: 0.1836 - feature_loss: 0.5436\n",
      "Epoch 00216: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7273 - output_loss: 0.1838 - feature_loss: 0.5434 - val_loss: 0.7862 - val_output_loss: 0.2230 - val_feature_loss: 0.5631\n",
      "Epoch 217/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7121 - output_loss: 0.1762 - feature_loss: 0.5359\n",
      "Epoch 00217: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7118 - output_loss: 0.1762 - feature_loss: 0.5356 - val_loss: 0.7488 - val_output_loss: 0.1946 - val_feature_loss: 0.5542\n",
      "Epoch 218/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7181 - output_loss: 0.1770 - feature_loss: 0.5410\n",
      "Epoch 00218: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.7178 - output_loss: 0.1771 - feature_loss: 0.5407 - val_loss: 0.7320 - val_output_loss: 0.1956 - val_feature_loss: 0.5364\n",
      "Epoch 219/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7216 - output_loss: 0.1821 - feature_loss: 0.5395\n",
      "Epoch 00219: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7211 - output_loss: 0.1820 - feature_loss: 0.5390 - val_loss: 0.7051 - val_output_loss: 0.1774 - val_feature_loss: 0.5277\n",
      "Epoch 220/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7075 - output_loss: 0.1708 - feature_loss: 0.5367\n",
      "Epoch 00220: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7067 - output_loss: 0.1708 - feature_loss: 0.5360 - val_loss: 0.6789 - val_output_loss: 0.1700 - val_feature_loss: 0.5088\n",
      "Epoch 221/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7071 - output_loss: 0.1720 - feature_loss: 0.5351\n",
      "Epoch 00221: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7067 - output_loss: 0.1721 - feature_loss: 0.5345 - val_loss: 0.7084 - val_output_loss: 0.1843 - val_feature_loss: 0.5241\n",
      "Epoch 222/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6685 - output_loss: 0.1583 - feature_loss: 0.5103\n",
      "Epoch 00222: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6682 - output_loss: 0.1583 - feature_loss: 0.5099 - val_loss: 0.7006 - val_output_loss: 0.1914 - val_feature_loss: 0.5092\n",
      "Epoch 223/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6939 - output_loss: 0.1693 - feature_loss: 0.5246\n",
      "Epoch 00223: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6936 - output_loss: 0.1695 - feature_loss: 0.5240 - val_loss: 0.6878 - val_output_loss: 0.1825 - val_feature_loss: 0.5053\n",
      "Epoch 224/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6817 - output_loss: 0.1628 - feature_loss: 0.5189\n",
      "Epoch 00224: val_output_loss did not improve from 0.16383\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6814 - output_loss: 0.1630 - feature_loss: 0.5184 - val_loss: 0.6699 - val_output_loss: 0.1681 - val_feature_loss: 0.5017\n",
      "Epoch 225/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6798 - output_loss: 0.1622 - feature_loss: 0.5176\n",
      "Epoch 00225: val_output_loss improved from 0.16383 to 0.15837, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6809 - output_loss: 0.1629 - feature_loss: 0.5180 - val_loss: 0.6367 - val_output_loss: 0.1584 - val_feature_loss: 0.4784\n",
      "Epoch 226/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6937 - output_loss: 0.1673 - feature_loss: 0.5263\n",
      "Epoch 00226: val_output_loss did not improve from 0.15837\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6924 - output_loss: 0.1670 - feature_loss: 0.5254 - val_loss: 0.6850 - val_output_loss: 0.1711 - val_feature_loss: 0.5139\n",
      "Epoch 227/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6858 - output_loss: 0.1660 - feature_loss: 0.5198\n",
      "Epoch 00227: val_output_loss did not improve from 0.15837\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6861 - output_loss: 0.1664 - feature_loss: 0.5197 - val_loss: 0.6338 - val_output_loss: 0.1605 - val_feature_loss: 0.4733\n",
      "Epoch 228/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7038 - output_loss: 0.1757 - feature_loss: 0.5281\n",
      "Epoch 00228: val_output_loss improved from 0.15837 to 0.15761, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7029 - output_loss: 0.1754 - feature_loss: 0.5275 - val_loss: 0.6359 - val_output_loss: 0.1576 - val_feature_loss: 0.4783\n",
      "Epoch 229/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6963 - output_loss: 0.1670 - feature_loss: 0.5293\n",
      "Epoch 00229: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6960 - output_loss: 0.1672 - feature_loss: 0.5288 - val_loss: 0.7087 - val_output_loss: 0.1794 - val_feature_loss: 0.5293\n",
      "Epoch 230/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7038 - output_loss: 0.1737 - feature_loss: 0.5301\n",
      "Epoch 00230: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7044 - output_loss: 0.1743 - feature_loss: 0.5301 - val_loss: 0.6460 - val_output_loss: 0.1783 - val_feature_loss: 0.4678\n",
      "Epoch 231/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6780 - output_loss: 0.1634 - feature_loss: 0.5146\n",
      "Epoch 00231: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6791 - output_loss: 0.1641 - feature_loss: 0.5150 - val_loss: 0.6918 - val_output_loss: 0.1774 - val_feature_loss: 0.5144\n",
      "Epoch 232/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6722 - output_loss: 0.1618 - feature_loss: 0.5104\n",
      "Epoch 00232: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6726 - output_loss: 0.1621 - feature_loss: 0.5104 - val_loss: 0.6987 - val_output_loss: 0.1801 - val_feature_loss: 0.5186\n",
      "Epoch 233/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6509 - output_loss: 0.1532 - feature_loss: 0.4977\n",
      "Epoch 00233: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6499 - output_loss: 0.1529 - feature_loss: 0.4970 - val_loss: 0.7031 - val_output_loss: 0.1849 - val_feature_loss: 0.5183\n",
      "Epoch 234/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.7074 - output_loss: 0.1734 - feature_loss: 0.5340\n",
      "Epoch 00234: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.7071 - output_loss: 0.1734 - feature_loss: 0.5337 - val_loss: 0.7441 - val_output_loss: 0.1974 - val_feature_loss: 0.5468\n",
      "Epoch 235/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6805 - output_loss: 0.1649 - feature_loss: 0.5156\n",
      "Epoch 00235: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6806 - output_loss: 0.1651 - feature_loss: 0.5155 - val_loss: 0.6816 - val_output_loss: 0.1763 - val_feature_loss: 0.5053\n",
      "Epoch 236/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6776 - output_loss: 0.1603 - feature_loss: 0.5173\n",
      "Epoch 00236: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6768 - output_loss: 0.1601 - feature_loss: 0.5167 - val_loss: 0.6759 - val_output_loss: 0.1693 - val_feature_loss: 0.5065\n",
      "Epoch 237/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6738 - output_loss: 0.1619 - feature_loss: 0.5119\n",
      "Epoch 00237: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6731 - output_loss: 0.1618 - feature_loss: 0.5113 - val_loss: 0.6615 - val_output_loss: 0.1670 - val_feature_loss: 0.4945\n",
      "Epoch 238/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6695 - output_loss: 0.1585 - feature_loss: 0.5110\n",
      "Epoch 00238: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6707 - output_loss: 0.1592 - feature_loss: 0.5115 - val_loss: 0.6332 - val_output_loss: 0.1589 - val_feature_loss: 0.4743\n",
      "Epoch 239/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6715 - output_loss: 0.1602 - feature_loss: 0.5113\n",
      "Epoch 00239: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6709 - output_loss: 0.1602 - feature_loss: 0.5107 - val_loss: 0.6977 - val_output_loss: 0.1871 - val_feature_loss: 0.5106\n",
      "Epoch 240/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6525 - output_loss: 0.1535 - feature_loss: 0.4989\n",
      "Epoch 00240: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6522 - output_loss: 0.1536 - feature_loss: 0.4985 - val_loss: 0.6389 - val_output_loss: 0.1653 - val_feature_loss: 0.4736\n",
      "Epoch 241/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6455 - output_loss: 0.1511 - feature_loss: 0.4945\n",
      "Epoch 00241: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6454 - output_loss: 0.1514 - feature_loss: 0.4941 - val_loss: 0.6601 - val_output_loss: 0.1719 - val_feature_loss: 0.4881\n",
      "Epoch 242/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6673 - output_loss: 0.1582 - feature_loss: 0.5092\n",
      "Epoch 00242: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6679 - output_loss: 0.1586 - feature_loss: 0.5094 - val_loss: 0.6998 - val_output_loss: 0.1746 - val_feature_loss: 0.5253\n",
      "Epoch 243/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6556 - output_loss: 0.1553 - feature_loss: 0.5003\n",
      "Epoch 00243: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6558 - output_loss: 0.1556 - feature_loss: 0.5002 - val_loss: 0.6717 - val_output_loss: 0.1696 - val_feature_loss: 0.5021\n",
      "Epoch 244/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6572 - output_loss: 0.1581 - feature_loss: 0.4991\n",
      "Epoch 00244: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6568 - output_loss: 0.1582 - feature_loss: 0.4986 - val_loss: 0.6572 - val_output_loss: 0.1627 - val_feature_loss: 0.4945\n",
      "Epoch 245/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6588 - output_loss: 0.1578 - feature_loss: 0.5010\n",
      "Epoch 00245: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6592 - output_loss: 0.1583 - feature_loss: 0.5009 - val_loss: 0.8114 - val_output_loss: 0.2418 - val_feature_loss: 0.5696\n",
      "Epoch 246/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6783 - output_loss: 0.1663 - feature_loss: 0.5120\n",
      "Epoch 00246: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6779 - output_loss: 0.1664 - feature_loss: 0.5115 - val_loss: 0.6962 - val_output_loss: 0.1741 - val_feature_loss: 0.5222\n",
      "Epoch 247/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6672 - output_loss: 0.1600 - feature_loss: 0.5072\n",
      "Epoch 00247: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6671 - output_loss: 0.1602 - feature_loss: 0.5069 - val_loss: 0.7273 - val_output_loss: 0.1914 - val_feature_loss: 0.5359\n",
      "Epoch 248/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6553 - output_loss: 0.1544 - feature_loss: 0.5009\n",
      "Epoch 00248: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6548 - output_loss: 0.1544 - feature_loss: 0.5004 - val_loss: 0.6952 - val_output_loss: 0.1802 - val_feature_loss: 0.5150\n",
      "Epoch 249/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6763 - output_loss: 0.1629 - feature_loss: 0.5135\n",
      "Epoch 00249: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6748 - output_loss: 0.1626 - feature_loss: 0.5122 - val_loss: 0.6750 - val_output_loss: 0.1621 - val_feature_loss: 0.5129\n",
      "Epoch 250/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6720 - output_loss: 0.1622 - feature_loss: 0.5098\n",
      "Epoch 00250: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6714 - output_loss: 0.1620 - feature_loss: 0.5094 - val_loss: 0.7089 - val_output_loss: 0.1895 - val_feature_loss: 0.5194\n",
      "Epoch 251/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6732 - output_loss: 0.1600 - feature_loss: 0.5131\n",
      "Epoch 00251: val_output_loss did not improve from 0.15761\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6732 - output_loss: 0.1605 - feature_loss: 0.5127 - val_loss: 0.6525 - val_output_loss: 0.1701 - val_feature_loss: 0.4824\n",
      "Epoch 252/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6822 - output_loss: 0.1679 - feature_loss: 0.5143\n",
      "Epoch 00252: val_output_loss improved from 0.15761 to 0.15695, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6813 - output_loss: 0.1679 - feature_loss: 0.5134 - val_loss: 0.6190 - val_output_loss: 0.1570 - val_feature_loss: 0.4621\n",
      "Epoch 253/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6703 - output_loss: 0.1625 - feature_loss: 0.5077\n",
      "Epoch 00253: val_output_loss did not improve from 0.15695\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6694 - output_loss: 0.1621 - feature_loss: 0.5073 - val_loss: 0.6422 - val_output_loss: 0.1598 - val_feature_loss: 0.4823\n",
      "Epoch 254/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6480 - output_loss: 0.1516 - feature_loss: 0.4965\n",
      "Epoch 00254: val_output_loss improved from 0.15695 to 0.14607, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6477 - output_loss: 0.1515 - feature_loss: 0.4962 - val_loss: 0.6092 - val_output_loss: 0.1461 - val_feature_loss: 0.4631\n",
      "Epoch 255/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6433 - output_loss: 0.1494 - feature_loss: 0.4940\n",
      "Epoch 00255: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6425 - output_loss: 0.1491 - feature_loss: 0.4934 - val_loss: 0.6204 - val_output_loss: 0.1616 - val_feature_loss: 0.4588\n",
      "Epoch 256/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6499 - output_loss: 0.1563 - feature_loss: 0.4936\n",
      "Epoch 00256: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6490 - output_loss: 0.1561 - feature_loss: 0.4929 - val_loss: 0.6103 - val_output_loss: 0.1566 - val_feature_loss: 0.4537\n",
      "Epoch 257/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6404 - output_loss: 0.1539 - feature_loss: 0.4865\n",
      "Epoch 00257: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6404 - output_loss: 0.1540 - feature_loss: 0.4864 - val_loss: 0.6313 - val_output_loss: 0.1623 - val_feature_loss: 0.4690\n",
      "Epoch 258/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6519 - output_loss: 0.1558 - feature_loss: 0.4961\n",
      "Epoch 00258: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6518 - output_loss: 0.1557 - feature_loss: 0.4961 - val_loss: 0.6529 - val_output_loss: 0.1630 - val_feature_loss: 0.4899\n",
      "Epoch 259/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6488 - output_loss: 0.1543 - feature_loss: 0.4945\n",
      "Epoch 00259: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6488 - output_loss: 0.1547 - feature_loss: 0.4942 - val_loss: 0.6291 - val_output_loss: 0.1646 - val_feature_loss: 0.4645\n",
      "Epoch 260/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6352 - output_loss: 0.1506 - feature_loss: 0.4846\n",
      "Epoch 00260: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6347 - output_loss: 0.1506 - feature_loss: 0.4841 - val_loss: 0.6464 - val_output_loss: 0.1643 - val_feature_loss: 0.4821\n",
      "Epoch 261/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6450 - output_loss: 0.1531 - feature_loss: 0.4920\n",
      "Epoch 00261: val_output_loss did not improve from 0.14607\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6445 - output_loss: 0.1532 - feature_loss: 0.4913 - val_loss: 0.6123 - val_output_loss: 0.1519 - val_feature_loss: 0.4604\n",
      "Epoch 262/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6470 - output_loss: 0.1507 - feature_loss: 0.4963\n",
      "Epoch 00262: val_output_loss improved from 0.14607 to 0.14595, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6464 - output_loss: 0.1506 - feature_loss: 0.4958 - val_loss: 0.6113 - val_output_loss: 0.1460 - val_feature_loss: 0.4654\n",
      "Epoch 263/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6478 - output_loss: 0.1569 - feature_loss: 0.4909\n",
      "Epoch 00263: val_output_loss improved from 0.14595 to 0.14329, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6468 - output_loss: 0.1568 - feature_loss: 0.4900 - val_loss: 0.6092 - val_output_loss: 0.1433 - val_feature_loss: 0.4659\n",
      "Epoch 264/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6254 - output_loss: 0.1469 - feature_loss: 0.4785\n",
      "Epoch 00264: val_output_loss did not improve from 0.14329\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6249 - output_loss: 0.1467 - feature_loss: 0.4781 - val_loss: 0.6225 - val_output_loss: 0.1502 - val_feature_loss: 0.4723\n",
      "Epoch 265/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6414 - output_loss: 0.1487 - feature_loss: 0.4927\n",
      "Epoch 00265: val_output_loss did not improve from 0.14329\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6406 - output_loss: 0.1485 - feature_loss: 0.4921 - val_loss: 0.7033 - val_output_loss: 0.1872 - val_feature_loss: 0.5161\n",
      "Epoch 266/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6620 - output_loss: 0.1599 - feature_loss: 0.5020\n",
      "Epoch 00266: val_output_loss did not improve from 0.14329\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6612 - output_loss: 0.1597 - feature_loss: 0.5015 - val_loss: 0.6216 - val_output_loss: 0.1505 - val_feature_loss: 0.4711\n",
      "Epoch 267/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6183 - output_loss: 0.1434 - feature_loss: 0.4749\n",
      "Epoch 00267: val_output_loss did not improve from 0.14329\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6185 - output_loss: 0.1437 - feature_loss: 0.4748 - val_loss: 0.6224 - val_output_loss: 0.1490 - val_feature_loss: 0.4734\n",
      "Epoch 268/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6210 - output_loss: 0.1479 - feature_loss: 0.4731\n",
      "Epoch 00268: val_output_loss improved from 0.14329 to 0.14149, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6205 - output_loss: 0.1480 - feature_loss: 0.4725 - val_loss: 0.5920 - val_output_loss: 0.1415 - val_feature_loss: 0.4505\n",
      "Epoch 269/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6418 - output_loss: 0.1523 - feature_loss: 0.4895\n",
      "Epoch 00269: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6412 - output_loss: 0.1523 - feature_loss: 0.4889 - val_loss: 0.6495 - val_output_loss: 0.1645 - val_feature_loss: 0.4850\n",
      "Epoch 270/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6687 - output_loss: 0.1642 - feature_loss: 0.5045\n",
      "Epoch 00270: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6677 - output_loss: 0.1639 - feature_loss: 0.5038 - val_loss: 0.6433 - val_output_loss: 0.1546 - val_feature_loss: 0.4887\n",
      "Epoch 271/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6304 - output_loss: 0.1509 - feature_loss: 0.4795\n",
      "Epoch 00271: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6307 - output_loss: 0.1512 - feature_loss: 0.4795 - val_loss: 0.6459 - val_output_loss: 0.1652 - val_feature_loss: 0.4806\n",
      "Epoch 272/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6391 - output_loss: 0.1501 - feature_loss: 0.4890\n",
      "Epoch 00272: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6390 - output_loss: 0.1505 - feature_loss: 0.4884 - val_loss: 0.6547 - val_output_loss: 0.1580 - val_feature_loss: 0.4966\n",
      "Epoch 273/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6364 - output_loss: 0.1514 - feature_loss: 0.4850\n",
      "Epoch 00273: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6367 - output_loss: 0.1520 - feature_loss: 0.4847 - val_loss: 0.6599 - val_output_loss: 0.1584 - val_feature_loss: 0.5014\n",
      "Epoch 274/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6401 - output_loss: 0.1524 - feature_loss: 0.4878\n",
      "Epoch 00274: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6393 - output_loss: 0.1523 - feature_loss: 0.4870 - val_loss: 0.6304 - val_output_loss: 0.1500 - val_feature_loss: 0.4804\n",
      "Epoch 275/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6260 - output_loss: 0.1480 - feature_loss: 0.4781\n",
      "Epoch 00275: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6253 - output_loss: 0.1479 - feature_loss: 0.4775 - val_loss: 0.6003 - val_output_loss: 0.1491 - val_feature_loss: 0.4512\n",
      "Epoch 276/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6218 - output_loss: 0.1448 - feature_loss: 0.4770\n",
      "Epoch 00276: val_output_loss did not improve from 0.14149\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6212 - output_loss: 0.1447 - feature_loss: 0.4765 - val_loss: 0.6421 - val_output_loss: 0.1576 - val_feature_loss: 0.4845\n",
      "Epoch 277/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6259 - output_loss: 0.1503 - feature_loss: 0.4756\n",
      "Epoch 00277: val_output_loss improved from 0.14149 to 0.13613, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6262 - output_loss: 0.1505 - feature_loss: 0.4757 - val_loss: 0.5890 - val_output_loss: 0.1361 - val_feature_loss: 0.4529\n",
      "Epoch 278/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6323 - output_loss: 0.1493 - feature_loss: 0.4831\n",
      "Epoch 00278: val_output_loss did not improve from 0.13613\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6333 - output_loss: 0.1502 - feature_loss: 0.4831 - val_loss: 0.6213 - val_output_loss: 0.1487 - val_feature_loss: 0.4727\n",
      "Epoch 279/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6343 - output_loss: 0.1487 - feature_loss: 0.4857\n",
      "Epoch 00279: val_output_loss did not improve from 0.13613\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6337 - output_loss: 0.1489 - feature_loss: 0.4848 - val_loss: 0.5893 - val_output_loss: 0.1388 - val_feature_loss: 0.4504\n",
      "Epoch 280/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6280 - output_loss: 0.1487 - feature_loss: 0.4793\n",
      "Epoch 00280: val_output_loss improved from 0.13613 to 0.13272, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6275 - output_loss: 0.1487 - feature_loss: 0.4788 - val_loss: 0.5657 - val_output_loss: 0.1327 - val_feature_loss: 0.4330\n",
      "Epoch 281/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6205 - output_loss: 0.1445 - feature_loss: 0.4760\n",
      "Epoch 00281: val_output_loss did not improve from 0.13272\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6197 - output_loss: 0.1444 - feature_loss: 0.4753 - val_loss: 0.6467 - val_output_loss: 0.1561 - val_feature_loss: 0.4906\n",
      "Epoch 282/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6258 - output_loss: 0.1454 - feature_loss: 0.4804\n",
      "Epoch 00282: val_output_loss improved from 0.13272 to 0.13122, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6252 - output_loss: 0.1453 - feature_loss: 0.4798 - val_loss: 0.5701 - val_output_loss: 0.1312 - val_feature_loss: 0.4389\n",
      "Epoch 283/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6118 - output_loss: 0.1412 - feature_loss: 0.4706\n",
      "Epoch 00283: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6120 - output_loss: 0.1415 - feature_loss: 0.4704 - val_loss: 0.6458 - val_output_loss: 0.1703 - val_feature_loss: 0.4755\n",
      "Epoch 284/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6321 - output_loss: 0.1506 - feature_loss: 0.4815\n",
      "Epoch 00284: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6317 - output_loss: 0.1505 - feature_loss: 0.4811 - val_loss: 0.6410 - val_output_loss: 0.1649 - val_feature_loss: 0.4761\n",
      "Epoch 285/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6187 - output_loss: 0.1461 - feature_loss: 0.4726\n",
      "Epoch 00285: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6205 - output_loss: 0.1470 - feature_loss: 0.4735 - val_loss: 0.6255 - val_output_loss: 0.1537 - val_feature_loss: 0.4718\n",
      "Epoch 286/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6258 - output_loss: 0.1494 - feature_loss: 0.4764\n",
      "Epoch 00286: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6256 - output_loss: 0.1494 - feature_loss: 0.4763 - val_loss: 0.6405 - val_output_loss: 0.1627 - val_feature_loss: 0.4778\n",
      "Epoch 287/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6197 - output_loss: 0.1469 - feature_loss: 0.4728\n",
      "Epoch 00287: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6188 - output_loss: 0.1468 - feature_loss: 0.4720 - val_loss: 0.5972 - val_output_loss: 0.1376 - val_feature_loss: 0.4596\n",
      "Epoch 288/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6114 - output_loss: 0.1392 - feature_loss: 0.4723\n",
      "Epoch 00288: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6100 - output_loss: 0.1389 - feature_loss: 0.4711 - val_loss: 0.6002 - val_output_loss: 0.1464 - val_feature_loss: 0.4538\n",
      "Epoch 289/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6152 - output_loss: 0.1437 - feature_loss: 0.4715\n",
      "Epoch 00289: val_output_loss did not improve from 0.13122\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6155 - output_loss: 0.1439 - feature_loss: 0.4716 - val_loss: 0.5878 - val_output_loss: 0.1420 - val_feature_loss: 0.4458\n",
      "Epoch 290/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6249 - output_loss: 0.1490 - feature_loss: 0.4759\n",
      "Epoch 00290: val_output_loss improved from 0.13122 to 0.13117, saving model to ../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6240 - output_loss: 0.1489 - feature_loss: 0.4752 - val_loss: 0.5334 - val_output_loss: 0.1312 - val_feature_loss: 0.4022\n",
      "Epoch 291/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5845 - output_loss: 0.1324 - feature_loss: 0.4521\n",
      "Epoch 00291: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5850 - output_loss: 0.1327 - feature_loss: 0.4523 - val_loss: 0.5849 - val_output_loss: 0.1467 - val_feature_loss: 0.4382\n",
      "Epoch 292/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6183 - output_loss: 0.1436 - feature_loss: 0.4746\n",
      "Epoch 00292: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6172 - output_loss: 0.1434 - feature_loss: 0.4738 - val_loss: 0.6391 - val_output_loss: 0.1622 - val_feature_loss: 0.4770\n",
      "Epoch 293/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6111 - output_loss: 0.1438 - feature_loss: 0.4673\n",
      "Epoch 00293: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6104 - output_loss: 0.1437 - feature_loss: 0.4667 - val_loss: 0.5886 - val_output_loss: 0.1466 - val_feature_loss: 0.4420\n",
      "Epoch 294/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5950 - output_loss: 0.1385 - feature_loss: 0.4566\n",
      "Epoch 00294: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5953 - output_loss: 0.1388 - feature_loss: 0.4565 - val_loss: 0.5686 - val_output_loss: 0.1402 - val_feature_loss: 0.4284\n",
      "Epoch 295/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6214 - output_loss: 0.1452 - feature_loss: 0.4762\n",
      "Epoch 00295: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6217 - output_loss: 0.1457 - feature_loss: 0.4759 - val_loss: 0.7083 - val_output_loss: 0.1867 - val_feature_loss: 0.5216\n",
      "Epoch 296/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6307 - output_loss: 0.1490 - feature_loss: 0.4817\n",
      "Epoch 00296: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6308 - output_loss: 0.1493 - feature_loss: 0.4815 - val_loss: 0.6146 - val_output_loss: 0.1497 - val_feature_loss: 0.4649\n",
      "Epoch 297/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6048 - output_loss: 0.1441 - feature_loss: 0.4607\n",
      "Epoch 00297: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6052 - output_loss: 0.1445 - feature_loss: 0.4608 - val_loss: 0.6368 - val_output_loss: 0.1532 - val_feature_loss: 0.4836\n",
      "Epoch 298/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6098 - output_loss: 0.1424 - feature_loss: 0.4674\n",
      "Epoch 00298: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6095 - output_loss: 0.1426 - feature_loss: 0.4669 - val_loss: 0.5798 - val_output_loss: 0.1413 - val_feature_loss: 0.4385\n",
      "Epoch 299/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6108 - output_loss: 0.1410 - feature_loss: 0.4697\n",
      "Epoch 00299: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6114 - output_loss: 0.1417 - feature_loss: 0.4697 - val_loss: 0.5953 - val_output_loss: 0.1463 - val_feature_loss: 0.4490\n",
      "Epoch 300/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6222 - output_loss: 0.1469 - feature_loss: 0.4753\n",
      "Epoch 00300: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6223 - output_loss: 0.1473 - feature_loss: 0.4749 - val_loss: 0.5943 - val_output_loss: 0.1431 - val_feature_loss: 0.4512\n",
      "Epoch 301/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6238 - output_loss: 0.1468 - feature_loss: 0.4770\n",
      "Epoch 00301: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6252 - output_loss: 0.1478 - feature_loss: 0.4774 - val_loss: 0.6217 - val_output_loss: 0.1606 - val_feature_loss: 0.4611\n",
      "Epoch 302/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6302 - output_loss: 0.1524 - feature_loss: 0.4777\n",
      "Epoch 00302: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6288 - output_loss: 0.1521 - feature_loss: 0.4767 - val_loss: 0.5956 - val_output_loss: 0.1525 - val_feature_loss: 0.4430\n",
      "Epoch 303/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6135 - output_loss: 0.1450 - feature_loss: 0.4685\n",
      "Epoch 00303: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6140 - output_loss: 0.1453 - feature_loss: 0.4687 - val_loss: 0.6027 - val_output_loss: 0.1470 - val_feature_loss: 0.4557\n",
      "Epoch 304/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6012 - output_loss: 0.1411 - feature_loss: 0.4601\n",
      "Epoch 00304: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6006 - output_loss: 0.1410 - feature_loss: 0.4596 - val_loss: 0.6083 - val_output_loss: 0.1647 - val_feature_loss: 0.4436\n",
      "Epoch 305/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5879 - output_loss: 0.1353 - feature_loss: 0.4526\n",
      "Epoch 00305: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5871 - output_loss: 0.1351 - feature_loss: 0.4520 - val_loss: 0.6320 - val_output_loss: 0.1548 - val_feature_loss: 0.4772\n",
      "Epoch 306/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5875 - output_loss: 0.1355 - feature_loss: 0.4520\n",
      "Epoch 00306: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5884 - output_loss: 0.1359 - feature_loss: 0.4525 - val_loss: 0.5945 - val_output_loss: 0.1424 - val_feature_loss: 0.4521\n",
      "Epoch 307/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6030 - output_loss: 0.1422 - feature_loss: 0.4608\n",
      "Epoch 00307: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6021 - output_loss: 0.1420 - feature_loss: 0.4600 - val_loss: 0.6513 - val_output_loss: 0.1650 - val_feature_loss: 0.4862\n",
      "Epoch 308/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5888 - output_loss: 0.1366 - feature_loss: 0.4522\n",
      "Epoch 00308: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5888 - output_loss: 0.1366 - feature_loss: 0.4522 - val_loss: 0.6538 - val_output_loss: 0.1656 - val_feature_loss: 0.4881\n",
      "Epoch 309/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5888 - output_loss: 0.1345 - feature_loss: 0.4543\n",
      "Epoch 00309: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5890 - output_loss: 0.1348 - feature_loss: 0.4542 - val_loss: 0.6053 - val_output_loss: 0.1479 - val_feature_loss: 0.4574\n",
      "Epoch 310/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5951 - output_loss: 0.1396 - feature_loss: 0.4555\n",
      "Epoch 00310: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5955 - output_loss: 0.1400 - feature_loss: 0.4555 - val_loss: 0.5989 - val_output_loss: 0.1536 - val_feature_loss: 0.4453\n",
      "Epoch 311/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5987 - output_loss: 0.1375 - feature_loss: 0.4613\n",
      "Epoch 00311: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5986 - output_loss: 0.1376 - feature_loss: 0.4611 - val_loss: 0.6114 - val_output_loss: 0.1521 - val_feature_loss: 0.4593\n",
      "Epoch 312/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5796 - output_loss: 0.1316 - feature_loss: 0.4480\n",
      "Epoch 00312: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5794 - output_loss: 0.1317 - feature_loss: 0.4476 - val_loss: 0.6124 - val_output_loss: 0.1477 - val_feature_loss: 0.4647\n",
      "Epoch 313/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6012 - output_loss: 0.1401 - feature_loss: 0.4611\n",
      "Epoch 00313: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6026 - output_loss: 0.1410 - feature_loss: 0.4617 - val_loss: 0.5634 - val_output_loss: 0.1322 - val_feature_loss: 0.4312\n",
      "Epoch 314/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5854 - output_loss: 0.1345 - feature_loss: 0.4509\n",
      "Epoch 00314: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5847 - output_loss: 0.1343 - feature_loss: 0.4504 - val_loss: 0.5768 - val_output_loss: 0.1342 - val_feature_loss: 0.4426\n",
      "Epoch 315/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5718 - output_loss: 0.1288 - feature_loss: 0.4430\n",
      "Epoch 00315: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5716 - output_loss: 0.1288 - feature_loss: 0.4429 - val_loss: 0.5978 - val_output_loss: 0.1389 - val_feature_loss: 0.4589\n",
      "Epoch 316/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.6128 - output_loss: 0.1449 - feature_loss: 0.4679\n",
      "Epoch 00316: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6127 - output_loss: 0.1451 - feature_loss: 0.4676 - val_loss: 0.6228 - val_output_loss: 0.1540 - val_feature_loss: 0.4688\n",
      "Epoch 317/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5843 - output_loss: 0.1330 - feature_loss: 0.4513\n",
      "Epoch 00317: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5849 - output_loss: 0.1332 - feature_loss: 0.4517 - val_loss: 0.6697 - val_output_loss: 0.1732 - val_feature_loss: 0.4966\n",
      "Epoch 318/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5892 - output_loss: 0.1364 - feature_loss: 0.4527\n",
      "Epoch 00318: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5878 - output_loss: 0.1361 - feature_loss: 0.4517 - val_loss: 0.5979 - val_output_loss: 0.1449 - val_feature_loss: 0.4529\n",
      "Epoch 319/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5620 - output_loss: 0.1273 - feature_loss: 0.4348\n",
      "Epoch 00319: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5616 - output_loss: 0.1272 - feature_loss: 0.4345 - val_loss: 0.5671 - val_output_loss: 0.1356 - val_feature_loss: 0.4314\n",
      "Epoch 320/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5858 - output_loss: 0.1338 - feature_loss: 0.4520\n",
      "Epoch 00320: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5861 - output_loss: 0.1341 - feature_loss: 0.4520 - val_loss: 0.5510 - val_output_loss: 0.1312 - val_feature_loss: 0.4198\n",
      "Epoch 321/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5984 - output_loss: 0.1382 - feature_loss: 0.4602\n",
      "Epoch 00321: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5985 - output_loss: 0.1384 - feature_loss: 0.4600 - val_loss: 0.6406 - val_output_loss: 0.1630 - val_feature_loss: 0.4775\n",
      "Epoch 322/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5845 - output_loss: 0.1341 - feature_loss: 0.4505\n",
      "Epoch 00322: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5837 - output_loss: 0.1339 - feature_loss: 0.4498 - val_loss: 0.5744 - val_output_loss: 0.1414 - val_feature_loss: 0.4330\n",
      "Epoch 323/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5869 - output_loss: 0.1348 - feature_loss: 0.4521\n",
      "Epoch 00323: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5872 - output_loss: 0.1350 - feature_loss: 0.4522 - val_loss: 0.6460 - val_output_loss: 0.1684 - val_feature_loss: 0.4777\n",
      "Epoch 324/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5999 - output_loss: 0.1413 - feature_loss: 0.4586\n",
      "Epoch 00324: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5995 - output_loss: 0.1412 - feature_loss: 0.4583 - val_loss: 0.5791 - val_output_loss: 0.1450 - val_feature_loss: 0.4341\n",
      "Epoch 325/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5891 - output_loss: 0.1376 - feature_loss: 0.4516\n",
      "Epoch 00325: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5881 - output_loss: 0.1373 - feature_loss: 0.4508 - val_loss: 0.6224 - val_output_loss: 0.1539 - val_feature_loss: 0.4685\n",
      "Epoch 326/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5787 - output_loss: 0.1309 - feature_loss: 0.4478\n",
      "Epoch 00326: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5786 - output_loss: 0.1309 - feature_loss: 0.4477 - val_loss: 0.6270 - val_output_loss: 0.1697 - val_feature_loss: 0.4573\n",
      "Epoch 327/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5513 - output_loss: 0.1248 - feature_loss: 0.4266\n",
      "Epoch 00327: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5517 - output_loss: 0.1249 - feature_loss: 0.4268 - val_loss: 0.5856 - val_output_loss: 0.1491 - val_feature_loss: 0.4364\n",
      "Epoch 328/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5689 - output_loss: 0.1290 - feature_loss: 0.4399\n",
      "Epoch 00328: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.5682 - output_loss: 0.1290 - feature_loss: 0.4392 - val_loss: 0.5606 - val_output_loss: 0.1392 - val_feature_loss: 0.4214\n",
      "Epoch 329/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5665 - output_loss: 0.1306 - feature_loss: 0.4359\n",
      "Epoch 00329: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5660 - output_loss: 0.1304 - feature_loss: 0.4356 - val_loss: 0.5700 - val_output_loss: 0.1401 - val_feature_loss: 0.4299\n",
      "Epoch 330/400\n",
      "92/93 [============================>.] - ETA: 0s - loss: 0.5663 - output_loss: 0.1296 - feature_loss: 0.4368\n",
      "Epoch 00330: val_output_loss did not improve from 0.13117\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5659 - output_loss: 0.1295 - feature_loss: 0.4363 - val_loss: 0.5756 - val_output_loss: 0.1450 - val_feature_loss: 0.4307\n",
      "Epoch 00330: early stopping\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "X_hr,y_stress,y_participant,X_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr_dalia_normalized.p','rb'))\n",
    "\n",
    "X_hr = X_hr.reshape(-1,30,1)\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,LeaveOneGroupOut,LeavePGroupsOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from keras.layers import Conv1D,Reshape,BatchNormalization,TimeDistributed, \\\n",
    "Dropout,Input,MaxPooling1D,Flatten,Dense,Input, GaussianNoise,LSTM, Bidirectional, Input\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer,LabelEncoder\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "train_participant = y_participant.copy()\n",
    "\n",
    "print(np.unique(y_participant),train_participant.shape)\n",
    "\n",
    "train_x = X_hr\n",
    "train_y = y_participant\n",
    "\n",
    "train_x, test_x, train_y, test_y,participant_ids_train, participant_ids_test = train_test_split(X_hr,\n",
    "                                                            train_participant,\n",
    "                                                            y_participant,\n",
    "                                                            test_size = 0.2,\n",
    "                                                            random_state=41,\n",
    "                                                            stratify=y_participant)\n",
    "train_x, val_x, train_y, val_y, participant_ids_train, participant_ids_val  = train_test_split(train_x,\n",
    "                                                            train_y,\n",
    "                                                            participant_ids_train,\n",
    "                                                            test_size = 0.1,\n",
    "                                                            random_state=41,\n",
    "                                                            stratify=participant_ids_train)\n",
    "# train_x.shape,test_x.shape,val_x.shape,train_y.shape,test_y.shape,val_y.shape,participant_ids_train.shape\n",
    "\n",
    "\n",
    "# def custom_loss(y_true,y_pred):\n",
    "    \n",
    "# #     print(y_true.shape)\n",
    "# #     print(y_pred[0].shape)\n",
    "# #     y_pred_output_class = y_pred\n",
    "# #     [0]\n",
    "# #     y_pred_output_embedding = y_pred[1]\n",
    "#     return tf.keras.losses.SparseCategoricalCrossentropy(y_true,y_pred_output_class) \n",
    "# + tfa.losses.TripletSemiHardLoss(y_true,y_pred_output_embedding)\n",
    "\n",
    "\n",
    "def custom_loss(embeddings):\n",
    "    def loss(y_true,y_pred):\n",
    "        return tf.keras.losses.SparseCategoricalCrossentropy(y_true,y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_model(input_shape=(30,1),act='relu',loss=\"categorical_crossentropy\",opt='adam',\n",
    "              n_classes=350,n_output = 15):\n",
    "    \n",
    "    model =  Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Reshape(input_shape))\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='linear',kernel_initializer='normal',padding='same'))\n",
    "    model.add(Conv1D(100,10,input_shape=input_shape,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(200,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Conv1D(300,10,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(50,2,activation='relu',kernel_initializer='normal',padding='same'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(n_classes//2,activation='relu'))\n",
    "    model.add(Dense(n_output//2,activation='relu'))\n",
    "#     model.add(Dense(n_classes,activation='softmax',kernel_initializer='normal'))\n",
    "    \n",
    "    input_ = Input(shape=input_shape)\n",
    "    embeddings = model(input_)\n",
    "    #     print(embeddings.shape)\n",
    "    softmax_activations = Dense(n_output,activation='sigmoid',name='feature1')(embeddings)\n",
    "    softmax_activations = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1),name='feature')(softmax_activations)\n",
    "    softmax_output = Dense(n_output,activation='softmax',name='output')(softmax_activations)\n",
    "    model1 = Model(inputs=[input_],outputs=[softmax_output,softmax_activations])\n",
    "    model1.compile(loss={'feature':tfa.losses.TripletSemiHardLoss(),'output':tf.keras.losses.SparseCategoricalCrossentropy()},\n",
    "                   optimizer=opt,\n",
    "                  loss_weights={'feature':1,'output':1})\n",
    "    return model1\n",
    "\n",
    "n_classes = 200\n",
    "n_output = len(np.unique(y_participant))\n",
    "model = get_model(input_shape=(30,1),n_classes=n_classes,n_output=n_output) \n",
    "model.summary()\n",
    "\n",
    "# model.layers[0]\n",
    "\n",
    "from keras.models import load_model\n",
    "filepath = '../model_files/base_cnn_60_seconds_ppg_hr_wesad_normalized.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_output_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "es = EarlyStopping(monitor='val_output_loss', mode='min', verbose=1,patience=40)\n",
    "callbacks_list = [es,checkpoint]\n",
    "history = model.fit(train_x,[train_y,train_y],validation_data=(val_x,[val_y,val_y]), epochs=400, \n",
    "                    batch_size=500,callbacks=callbacks_list,shuffle=True,verbose=1)\n",
    "\n",
    "# # # model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = model.predict(test_x)[1]\n",
    "test_y_pred = model.predict(test_x)[0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       898\n",
      "           1       0.99      0.98      0.99       909\n",
      "           2       0.95      0.97      0.96       787\n",
      "           3       0.95      0.97      0.96       868\n",
      "           4       0.97      0.96      0.96       928\n",
      "           5       0.99      0.97      0.98       785\n",
      "           6       0.89      0.99      0.94       518\n",
      "           7       0.93      0.98      0.95       907\n",
      "           8       0.99      0.98      0.98      1058\n",
      "           9       0.98      0.95      0.97       924\n",
      "          10       0.98      0.99      0.98       849\n",
      "          11       1.00      0.97      0.98       801\n",
      "          12       0.98      0.97      0.97       814\n",
      "          13       0.97      0.96      0.97       889\n",
      "          14       0.98      0.96      0.97       915\n",
      "\n",
      "    accuracy                           0.97     12850\n",
      "   macro avg       0.97      0.97      0.97     12850\n",
      "weighted avg       0.97      0.97      0.97     12850\n",
      "\n",
      "[[ 859    0    0    4    1    8    2    9    3    4    2    0    0    6\n",
      "     0]\n",
      " [   0  892    3    1    0    0    0    1    1    1    5    1    4    0\n",
      "     0]\n",
      " [   1    0  764   11    4    0    0    0    3    0    0    0    2    0\n",
      "     2]\n",
      " [   3    0    0  838    4    0   12   10    1    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    3    8  889    0    3   18    1    0    0    0    0    4\n",
      "     2]\n",
      " [   0    3    1    1    0  761    7    3    0    1    0    0    2    0\n",
      "     6]\n",
      " [   0    0    0    1    0    1  513    1    0    2    0    0    0    0\n",
      "     0]\n",
      " [   3    0    0    6    4    0    1  888    0    0    0    0    0    5\n",
      "     0]\n",
      " [   3    1    3    7    0    0    0    2 1037    4    1    0    0    0\n",
      "     0]\n",
      " [   2    0    0    0    0    0   37    1    2  881    0    0    0    1\n",
      "     0]\n",
      " [   1    3    3    0    0    1    0    0    0    0  837    0    2    2\n",
      "     0]\n",
      " [   0    2    0    0    0    1    0    0    0    0    6  776    6    3\n",
      "     7]\n",
      " [   2    1   14    2    1    0    1    4    0    0    0    0  789    0\n",
      "     0]\n",
      " [   8    0    0    0    7    0    1   14    0    3    0    0    0  855\n",
      "     1]\n",
      " [   0    0   13    1    6    0    0    7    4    0    5    0    0    2\n",
      "   877]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,test_y_pred))\n",
    "print(confusion_matrix(test_y,test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "train_embeddings_pca = TSNE(n_components=2).fit_transform(test_embeddings)\n",
    "plt.figure()\n",
    "plt.scatter(train_embeddings_pca[:,0],train_embeddings_pca[:,1],c=test_y)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_dalia_x,test_dalia_y_stress,test_dalia_y,test_dalia_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr_normalized.p',\n",
    "                                                                                 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dalia_x = test_dalia_x.reshape(-1,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dalia_embeddings = model.predict(test_dalia_x)[1]\n",
    "test_dalia_y_pred = model.predict(test_dalia_x)[0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_embeddings_pca = TSNE(n_components=2).fit_transform(test_dalia_embeddings)\n",
    "plt.figure()\n",
    "plt.scatter(train_embeddings_pca[:,0],train_embeddings_pca[:,1],c=test_dalia_y)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=(30,1),n_classes=n_classes,n_output=n_output,loss=custom_loss) \n",
    "model.summary()\n",
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def get_clusters(model,train_x,train_y):\n",
    "    train_embeddings = model.predict(train_x)\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    train_embeddings_pca = PCA(n_components=20).fit_transform(train_embeddings)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(train_embeddings_pca[:,0],train_embeddings_pca[:,1],c=train_y)\n",
    "    plt.show()\n",
    "get_clusters(model,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_dalia_x,test_dalia_y_stress,test_dalia_y,test_dalia_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr_dalia.p',\n",
    "                                                                                 'rb'))\n",
    "test_dalia_x = test_dalia_x.reshape(-1,30,1)\n",
    "get_clusters(model,test_dalia_x,test_dalia_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_rank_accuracy(train_embeddings,train_y,rank = 10):\n",
    "    distance_matrix = euclidean_distances(train_embeddings)\n",
    "    distance_matrix_2d = np.zeros((distance_matrix.shape[0],\n",
    "                               distance_matrix.shape[0],\n",
    "                               2))\n",
    "    distance_matrix_2d[:,:,0] = distance_matrix\n",
    "    train_y_matrix = np.concatenate([train_y.reshape(1,-1)]*distance_matrix.shape[0])\n",
    "    distance_matrix_2d[:,:,1] = train_y_matrix\n",
    "    match = 0\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        row = distance_matrix_2d[i]\n",
    "        row = row[row[:,0].argsort(),:]\n",
    "        if rank==1:\n",
    "            if train_y[i]==row[1,1]:\n",
    "                match+=1\n",
    "        else:\n",
    "            row = set(row[1:(rank+1)][:,1])\n",
    "            if train_y[i] in row:\n",
    "                match+=1\n",
    "    return match/distance_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1 = give_rank_accuracy(train_embeddings,train_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(train_embeddings,train_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(train_embeddings,train_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1 = give_rank_accuracy(test_embeddings,test_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(test_embeddings,test_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(test_embeddings,test_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,y_stress,test_y,X_time = pickle.load(open('../data/tabular_data_60_seconds_ppg_rr_dalia.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.reshape(-1,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = model.predict(test_x)\n",
    "rank_1 = give_rank_accuracy(test_embeddings,test_y,rank = 1)\n",
    "rank_5 = give_rank_accuracy(test_embeddings,test_y,rank = 5)\n",
    "rank_10 = give_rank_accuracy(test_embeddings,test_y,rank = 10)\n",
    "print(rank_1,rank_5,rank_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_y,train_y_pred))\n",
    "print(confusion_matrix(train_y,train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
